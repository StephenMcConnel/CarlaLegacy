\input pcparse % common TeX setup  @c -*-texinfo-*-
\input texinfo
@c %**start of header
@setfilename pcpatr.info
@settitle PC-PATR Reference Manual
@c %**end of header

@syncodeindex fn cp

@set TITLE PC-PATR Reference Manual
@set SUBTITLE a unification based syntactic parser
@set VERSION version 1.4.0
@set DATE November 2006
@set AUTHOR by Stephen McConnel (changes for v. 1.2.5-1.4.0 by H. Andrew Black)
@set COPYRIGHT Copyright @copyright{} 2000-2006 SIL International

@include front.txi

@c ----------------------------------------------------------------------------
@node    Top,       Introduction,  (dir),    (dir)
@comment node-name, next,          previous, up

@ifinfo
@ifclear txt
This is the reference manual for the PC-PATR program.
@end ifclear
@end ifinfo

@menu
* Introduction::
* PATR-II formalism::
* Running PC-PATR::
* Grammar file::
* Standard format::
* Lexicon file::
* AMPLE analysis file::
* Using morphological parsers::
* Index::
@end menu
@c ----------------------------------------------------------------------------
@node    Introduction, PATR-II formalism, Top,      Top
@comment node-name,    next,              previous, up
@chapter Introduction to the PC-PATR program

This document describes PC-PATR, an implementation of the PATR-II
computational linguistic formalism (plus a few enhancements) for personal
computers.  It is available for MS-DOS, Microsoft Windows, Macintosh, and
Unix.@footnote{The Microsoft Windows implementation uses the Microsoft C
QuickWin function, and the Macintosh implementation uses the Metrowerks C
SIOUX function.}

PC-PATR uses a left corner chart parser with these characteristics:

@itemize @bullet
@item
bottom-up parse with top-down filtering based on the categories
@item
left-to-right order@value{emdash}after each word is added to the chart, all
possible edges that can be derived up that point are computed as a
side-effect
@end itemize
@noindent
PC-PATR is still under development.  The author would appreciate
feedback directed to the following address:
@example

Stephen McConnel                 (972)708-7361 (office)
Language Software Development    (972)708-7561 (fax)
SIL International
7500 W. Camp Wisdom Road
Dallas, TX 75236                 steve@@acadcomp.sil.org
U.S.A.                        or Stephen_McConnel@@sil.org

@end example

@c ----------------------------------------------------------------------------
@node    PATR-II formalism, Running PC-PATR, Introduction,      Top
@chapter The PATR-II Formalism

The PATR-II formalism can be viewed as a computer language for
encoding linguistic information.  It does not presuppose any particular
theory of syntax.  It was originally developed by Stuart M. Shieber at
Stanford University in the early 1980's (Shieber 1984, Shieber 1986).
A PATR-II grammar consists of a set of rules and a lexicon.  Each
rule consists of a context-free @emph{phrase structure rule} and a set
of @emph{feature constraints}, that is, @emph{unifications} on the
@emph{feature structures} associated with the constituents of the
phrase structure rules.  The lexicon provides the items that can
replace the terminal symbols of the phrase structure rules, that is,
the words of the language together with their relevant features.

@menu
* Phrase structure rules::
* Feature structures::
* Unification::
* Feature constraints::
* The lexicon::
@end menu

@c ----------------------------------------------------------------------------
@node Phrase structure rules, Feature structures, PATR-II formalism, PATR-II formalism
@section Phrase structure rules

Context-free phrase structure rules should be familiar to anyone who
has studied either linguistic theory or computer science.  They look
like this:
@example

LHS -> RHS_1 RHS_2 @dots{}

@end example
@noindent
@samp{LHS} (the symbol to the left of the arrow) is a nonterminal
symbol for the type of phrase that is being described.  To the right of
the arrow is an ordered list of the constituents of the phrase.  These
constituents are either nonterminal symbols, appearing on the left hand
side of some rule in the grammar, or terminal symbols, representing
basic classes of elements from the lexicon.  These basic classes
usually correspond to what are commonly called @emph{parts of speech}.
In PATR-II, the terminal and nonterminal symbols are both
referred to as @emph{categories}.

@set c-fpsg 1
@example

@group
@b{Figure @value{c-fpsg}. Context-free phrase structure grammar}

Rule  S       -> NP VP (SubCl)
Rule  NP      -> @{(Det) (AdjP) N (PrepP)@} / PR
Rule  Det     -> DT / PR
Rule  VP      -> VerbalP (NP / AdjP) (AdvP)
Rule  VerbalP -> V
Rule  VerbalP -> AuxP V
Rule  AuxP    -> AUX (AuxP_1)
Rule  PrepP   -> PP NP
Rule  AdjP    -> (AV) AJ (AdjP_1)
Rule  AdvP    -> @{AV / PrepP@} (AdvP_1)
Rule  SubCl   -> CJ S
@end group

@end example

Consider the PC-PATR style context-free phrase structure grammar
in figure @value{c-fpsg}.  It has ten nonterminal symbols (S, NP,
Det, VP, VerbalP, AuxP, PrepP, AdjP, AdvP, and SubCl), and nine terminal
symbols (N, PR, DT, V, AUX, PP, AV, AJ, and CJ).  This grammar
describes a small subset of English sentences.  Several aspects of this
grammar are worth mentioning.

@enumerate
@item
Optional constituents (or sets of constituents) on the right hand
side are enclosed in parentheses.
@item
Alternative constituents (or sets of constituents) on the right
hand side are separated by slashes.
@item
Braces are used to group alternative sets of elements together,
so that alternations are not ambiguous.
@item
Symbols should not be repeated verbatim within a rule.  Repeated
symbols should be distinguished from each other by adding a different
index number to a symbol each time it is repeated.  Index numbers are
introduced by the underscore (@code{_}) character.
@end enumerate

@set sample-parse 2
@example

@group
@b{Figure @value{sample-parse}. Parse of sample English sentence}

			  S
			  /\
			 /  \
			/    \
		   /      \
		  /        \
		 /          \
		/            \
	  NP              VP
	  /\             /|\
	 /  \           / | \
	/    \         /  |  \
  Det     N  VerbalP NP   AdvP
   |      |     |     |     |
  DT     man    V    PR   PrepP
   |            |     |    /\
  the         sees   us   /  \
						 /    \
						PP     NP
						 |     /\
					   with   /  \
							 /    \
						   Det     N
							|      |
						   DT  telescope
							|
							a
@end group

@end example

@set pc-patr-parse 3
@example

@group
@b{Figure @value{pc-patr-parse}. Parse of sample sentence (PC-PATR output)}

				S
	  __________|__________
	 NP                  VP
   ___|____      _________|__________
  Det     N   VerbalP  NP         AdvP
   |     man     |      |           |
  DT             V     PR         PrepP
  the          sees    us      _____|______
							  PP         NP
							 with     ____|_____
									 Det       N
									  |    telescope
									 DT
									  a
@end group

@end example

@set parses-ambig 4
A significant amount of grammar development can be done just with
context-free phrase structure rules such as these.  For example,
parsing the sentence ``the man sees us with a telescope'' with this
simple grammar produces a parse tree like that shown in figure
@value{sample-parse}.  (In order to minimize the height of parse trees
without needing to use a graphical interface, PC-PATR actually draws
parse trees like the one shown in figure @value{pc-patr-parse}.)
Parsing the similar sentence ``we see the man with a telescope''
produces two different parses as shown in figure @value{parses-ambig},
correctly showing the ambiguity between whether we used a telescope to
see the man, or the man had a telescope when we saw him.

@example

@group
@b{Figure @value{parses-ambig}. Parses of an ambiguous English sentence}

			S_1
   __________|__________
 NP_2+               VP_4
   |      _____________|_____________
 PR_3+ VerbalP_5+ NP_7           AdvP_11
  we      |      ___|____           |
		V_6+  Det_8+  N_10+     PrepP_12+
		 see     |     man     _____|______
			   DT_9+        PP_13+     NP_14+
				the          with     ____|_____
								   Det_15+   N_17+
									  |    telescope
								   DT_16+
									  a

		S_18
   _______|________
 NP_2+          VP_19
   |      ________|________
 PR_3+ VerbalP_5+       NP_20
  we      |      _________|__________
		V_6+  Det_8+  N_10+     PrepP_12+
		 see     |     man     _____|______
			   DT_9+        PP_13+     NP_14+
				the          with     ____|_____
								   Det_15+   N_17+
									  |    telescope
								   DT_16+
									  a
@end group

@end example

A fundamental problem with context-free phrase structure grammars is
that they tend to grossly overgenerate.  For example, the sample
grammar would incorrectly recognize the sentence ``*he see the man with
a telescope'', assigning it tree structures similar to those shown in
figure @value{parses-ambig}.  With only the simple categories used by
context-free phrase structure rules, a very large number of rules are
required to accurately handle even a small subset of a language's
grammar.  This is the primary motivation behind feature structures, the
basic enhancement of PATR-II over context-free phrase structure
grammars.@footnote{Gazdar and Mellish (1989, pages
142@value{endash}147) discuss
why context-free phrase structure grammars are inadequate to model some
human languages.  The PATR-II formalism (unification of feature
structures added to the context-free phrase structure rules) is shown
to be adequate for those cases.}

@c ----------------------------------------------------------------------------
@node Feature structures, Unification, Phrase structure rules, PATR-II formalism
@section Feature structures

The basic data structure of the PATR-II formalism is called a
@emph{feature structure}.  A feature structure contains one or more
@emph{features}.  A feature consists of an attribute name and a value.
Feature structures are commonly written as attribute-value matrices
like this (example 1):
@example

@group
(1)     [ lex: telescope
		  cat: N ]
@end group

@end example
@noindent
where @emph{lex} and @emph{cat} are attribute names, and
@emph{telescope} and @emph{N} are the values for those attributes.  Note
that the feature structure is enclosed in brackets.  Each feature
occurs on a separate line, with the name coming first, followed by a
colon and then its value.  Feature names and (simple) values are single
words consisting of alphanumeric characters.

Feature structures can have either simple values, such as the example
above, or complex values, such as this (example 2):
@example

@group
(2)     [ lex:      telescope
		  cat:      N
		  gloss:    `telescope
		  head:     [ agr:    [ 3sg: + ]
					  number: SG
					  pos:    N
					  proper: -
					  verbal: - ]
		  root_pos: N ]
@end group

@end example
@noindent
where the value of the @emph{head} feature is another feature
structure, that also contains an embedded feature structure.  Feature
structures can be arbitrarily nested in this manner.

Portions of a feature structure can be referred to using the
@emph{path} notation.  A path is a sequence of one or more feature names
enclosed in angled brackets (@code{<>}).  For instance, examples
3@value{endash}5
would all be valid feature paths based on the feature structure of
example 2:
@example

@group
(3)     <head>
(4)     <head number>
(5)     <head agr 3sg>
@end group

@end example
@noindent
Paths are used in feature templates and feature constraints, described
below.

Different features within a feature structure can share values.  This
is not the same thing as two features having identical values.  In
Example 6 below, the @code{<head agr>} and
@code{<subj head agr>} features have identical values, but in
Example 7, they share the same value:

@example
@group
(6)     [ cat:  S
		  pred: [ cat:  VP
				  head: [ agr:    [ 3sg: + ]
						  finite: +
						  pos:    V
						  tense:  PAST
						  vform:  ED ] ]
		  subj: [ cat:  NP
				  head: [ agr:    [ 3sg: + ]
						  case:   NOM
						  number: SG
						  pos:    N
						  proper: -
						  verbal: - ] ] ]
@end group
@end example

@example
@group
(7)     [ cat:  S
		  pred: [ cat:  VP
				  head: [ agr:    $1[ 3sg: + ]
						  finite: +
						  pos:    V
						  tense:  PAST
						  vform:  ED ] ]
		  subj: [ cat:  NP
				  head: [ agr:    $1[ 3sg: + ]
						  case:   NOM
						  number: SG
						  pos:    N
						  proper: -
						  verbal: - ] ] ]
@end group
@end example

Shared values are indicated by the coindexing markers
@code{$1}, @code{$2}, and so on.

Note that upper and lower case letters used in feature names and values
are distinctive.  For example, @emph{NUMBER} is not the same as
@emph{Number} or @emph{number}.  (This is also true of the symbols used in
the context-free phrase structure rules.)

@c ----------------------------------------------------------------------------
@node Unification, Feature constraints, Feature structures, PATR-II formalism
@section Unification

@emph{Unification} is the basic operation applied to feature
structures in PC-PATR.  It consists of the merging of the
information from two feature structures.  Two feature structures can
unify if their common features have the same values, but do not unify
if any feature values conflict.

Consider the following feature structures:
@example

@group
(8)     [ agreement: [ number: singular
					   person: first ] ]
@end group

@group
(9)     [ agreement: [ number: singular ]
		  case:      nominative ]
@end group

@group
(10)    [ agreement: [ number: singular
					   person: third ] ]
@end group

@group
(11)    [ agreement: [ number: singular
					   person: first ]
		  case:      nominative ]
@end group

@group
(12)    [ agreement: [ number: singular
					   person: third ]
		  case:      nominative ]
@end group

@end example
@noindent
Feature 9 can unify with either feature 8
(producing feature 11) or feature 10 (producing
feature 12).  However, feature 8 cannot unify with
feature 10 due to the conflict in the values of their
@code{<agreement person>} features.

@c ----------------------------------------------------------------------------
@node Feature constraints, The lexicon, Unification, PATR-II formalism
@section Feature constraints

The feature constraints associated with phrase structure rules in PATR-II
consist of a set of unification expressions (the @emph{unification
constraints}).  Each unification expression has three parts, in this
order:
@enumerate
@item
a feature path, the first element of which is one of the symbols from
the phrase structure rule
@item
an equal sign (@code{=})
@item
either a simple value, or another feature path that also starts with a
symbol from the phrase structure rule
@end enumerate
As an example, consider the following PC-PATR rules:
@example

@group
(13)	Rule S -> NP VP (SubCl)
		<NP head agr>  = <VP head agr>
		<NP head case> = NOM
		<S subj>       = <NP>
		<S head>       = <VP head>
@end group

@group
(14)	Rule NP -> @{(Det) (AJ) N (PrepP)@} / PR
		<Det head number> = <N head number>
		<NP head>         = <N head>
		<NP head>         = <PR head>
@end group

@end example
@noindent
Rule 13 has two feature constraints that limit the co-occurrence of NP
and VP, and two feature constraints that build the feature structures for
S.  This highlights the dual purpose of feature constraints in PC-PATR:
limiting the co-occurrence of phrase structure elements and constructing
the feature structure for the element defined by a rule.  The first
constraint states that the NP and VP @code{<head agr>} features must
unify successfully, and also modifies both of those features if they do
unify.  The second constraint states that NP's @code{<head case>} feature
must either be equal to @code{NOM} or else be undefined.  In the latter
case, it is set equal to @code{NOM}.  The last two constraints create a
new feature structure for S from the feature structures for NP and VP.

Rule 14 illustrates another important point about feature unification
constraints:  they are applied only if they involve the phrase
structure constituents actually found for the rule.

@set pc-patr-grammar 5
@example

@group
@b{Figure @value{pc-patr-grammar}. PC-PATR grammar of English subset}

Rule  S -> NP VP (SubCl)
		<NP head agr>  = <VP head agr>
		<NP head case> = NOM
		<S subj> = <NP>
		<S pred> = <VP>
Rule  NP -> @{(Det) (AdjP) N (PrepP)@} / PR
		<Det head number> = <N head number>
		<NP head> = <N head>
		<NP head> = <PR head>
Rule  Det -> DT / PR
		<PR head case> = GEN
		<Det head> = <DT head>
		<Det head> = <PR head>
Rule  VP -> VerbalP (NP / AdjP) (AdvP)
		<NP head case>   = ACC
		<NP head verbal> = -
		<VP head> = <VerbalP head>
Rule  VerbalP -> V
		<V head finite> = +
		<VerbalP head>  = <V head>
Rule  VerbalP -> AuxP V
		<V head finite> = -
		<VerbalP head>  = <AuxP head>
Rule  AuxP -> AUX (AuxP_1)
		<AuxP head> = <AUX head>
Rule  PrepP -> PP NP
		<NP head case> = ACC
		<PrepP head> = <PP head>
Rule  AdjP -> (AV) AJ (AdjP_1)
Rule  AdvP -> @{AV / PrepP@} (AdvP_1)
Rule  SubCl -> CJ S
@end group

@end example

@set pc-patr-output 6
@example

@group
@b{Figure @value{pc-patr-output}. PC-PATR output with feature structure}

1:
				S
	  __________|__________
	 NP                  VP
   ___|____      _________|__________
  Det     N   VerbalP  NP         AdvP
   |     man     |      |           |
  DT             V     PR         PrepP
  the           saw    us      _____|______
							  PP         NP
							 with     ____|_____
									 Det       N
									  |    telescope
									 DT
									  a

S:
[ cat:   S
  pred:    [ cat:   VP
			 head:    [ agr:   $1[ 3sg:   + ]
						finite:+
						pos:   V
						tense: PAST
						vform: ED ] ]
  subj:    [ cat:   NP
			 head:    [ agr:   $1[ 3sg:   + ]
						case:  NOM
						number:SG
						pos:   N
						proper:-
						verbal:- ] ] ]

1 parse found
@end group

@end example

Figure @value{pc-patr-grammar} shows the grammar of
figure @value{c-fpsg} augmented with a number of feature constraints.
With this grammar (and a suitable lexicon), the parse output shown in
figure @value{sample-parse} would include the sentence feature
structure, as shown in figure @value{pc-patr-output}.  Note that the
@w{@code{<subj head agr>}} and @w{@code{<pred head agr>}} features
share a common value as a result of the feature constraint unifications
associated with the rule @w{@code{S -> NP VP (SubCl)}}.

PC-PATR allows disjunctive feature unification constraints with its
phrase structure rules.  Consider rules 15 and 16 below.  These two rules
have the same phrase structure rule part.  They can therefore be
collapsed into the single rule 17, which has a disjunction in its
unification constraints.
@example

@group
(15)	Rule CP -> NP C'        ; for wh questions with NP fronted
		<NP type wh> = +
		<C' moved A-bar> = <NP>
		<CP type wh> = <NP type wh>
		<CP type> = <C' type>
		<CP moved A-bar> = none
		<CP type root> = +          ; root clauses
		<CP type q> = +
		<CP type fin> = +
		<CP moved A> = none
		<CP moved head> = none
@end group

@group
(16)	Rule CP -> NP C'        ; for wh questions with NP fronted
		<NP type wh> = +
		<C' moved A-bar> = <NP>
		<CP type wh> = <NP type wh>
		<CP type> = <C' type>
		<CP moved A-bar> = none
		<CP type root> = -          ; non-root clauses
@end group

@group
(17)	Rule CP -> NP C'        ; for wh questions with NP fronted
		<NP type wh> = +
		<C' moved A-bar> = <NP>
		<CP type wh> = <NP type wh>
		<CP type> = <C' type>
		<CP moved A-bar> = none
		@{
		<CP type root> = +		; root clauses
		<CP type q> = +
		<CP type fin> = +
		<CP moved A> = none
		<CP moved head> = none
			/
		<CP type root> = -		; non-root clauses
		@}
@end group

@end example
@noindent
Not only does PC-PATR allow disjunctive unification constraints, but it
also allows disjunctive phrase structure rules.  Consider rule 18: it is
very similar to rule 17.  These two rules can be further combined to form
rule 19, which has disjunctions in both its phrase structure rule and its
unification constraints.
@example

@group
(18)	Rule CP -> PP C'        ; for wh questions with PP fronted
		<PP type wh> = +
		<C' moved A-bar> = <PP>
		<CP type wh> = <PP type wh>
		<CP type> = <C' type>
		<CP moved A-bar> = none
		@{
		<CP type root> = +		; root clauses
		<CP type q> = +
		<CP type fin> = +
		<CP moved A> = none
		<CP moved head> = none
			/
		<CP type root> = -		; non-root clauses
		@}
@end group

@group
(19)	; for wh questions with NP or PP fronted
	Rule CP -> @{ NP / PP @} C'
		<NP type wh> = +
		<C' moved A-bar> = <NP>
		<CP type wh> = <NP type wh>
		<PP type wh> = +
		<C' moved A-bar> = <PP>
		<CP type wh> = <PP type wh>
		<CP type> = <C' type>
		<CP moved A-bar> = none
		@{
		<CP type root> = +		; root clauses
		<CP type q> = +
		<CP type fin> = +
		<CP moved A> = none
		<CP moved head> = none
			/
		<CP type root> = -		; non-root clauses
		@}
@end group

@end example

Since the open brace (@code{@{}) introduces disjunctions both in the
phrase structure rule and in the unification constraints, care must be
taken to avoid confusing PC-PATR when it is loading the grammar
file.  The end of the phrase structure rule, and the beginning of the
unification constraints, is signaled either by the first constraint
beginning with an open angle bracket (@code{<}) or by a colon
(@code{:}).  If the first constraint is part of a disjunction, then the
phrase structure rule must end with a colon.  Otherwise, PC-PATR
will treat the unification constraint as part of the phrase structure
rule, and will shortly complain about syntax errors in the grammar
file.

Perhaps it should be noted that disjunctions in phrase structure rules
or unifications are expanded when the grammar file is read.  They serve
only as a convenience for the person writing the rules.

@c ----------------------------------------------------------------------------
@node The lexicon, , Feature constraints, PATR-II formalism
@section The lexicon

The lexicon provides the basic elements (atoms) of the grammar, which
are usually words.  Information like that shown in
feature 2 is provided for each lexicon entry.  Unlike
the original implementation of PATR-II, PC-PATR stores
the lexicon in a separate file from the grammar rules.
@ifset txt
See `Lexicon File'
@end ifset
@ifclear txt
@xref{Lexicon file},
@end ifclear
below for details.

@c ----------------------------------------------------------------------------
@node Running PC-PATR, Grammar file, PATR-II formalism, Top
@chapter Running PC-PATR

PC-PATR is an interactive program.  It has a few command line options,
but it is controlled primarily by commands typed at the keyboard (or
loaded from a file previously prepared).

@menu
* Command line options::
* Interactive commands::
@end menu

@c ----------------------------------------------------------------------------
@node Command line options, Interactive commands, Running PC-PATR, Running PC-PATR
@section PC-PATR Command Line Options

The PC-PATR program uses an old-fashioned command line interface
following the convention of options starting with a dash character
(@samp{-}).  The available options are listed below in alphabetical
order.  Those options which require an argument have the argument type
following the option letter.

@ftable @code
@item -a filename
loads the lexicon from an AMPLE analysis output file.

@item -g filename
loads the grammar from a PC-PATR grammar file.

@item -l filename
loads the lexicon from a PC-PATR lexicon file.

@item -t filename
opens a file containing one or more PC-PATR commands.
@ifset txt
See `Interactive Commands' below.
@end ifset
@ifclear txt
@xref{Interactive commands}.
@end ifclear
@end ftable

The following options exist only in beta-test versions of the program,
since they are used only for debugging.

@ftable @code
@item -/
increments the debugging level.  The default is zero (no debugging output).

@item -z filename
opens a file for recording a memory allocation log.

@item -Z address,count
traps the program at the point where @code{address} is allocated or
freed for the @code{count}'th time.
@end ftable

@c ----------------------------------------------------------------------------
@node Interactive commands, , Command line options, Running PC-PATR
@section Interactive Commands

Each of the commands available in PC-PATR is described below.  Each
command consists of one or more keywords followed by zero or more
arguments.  Keywords may be abbreviated to the minimum length necessary
to prevent ambiguity.

@menu
* cd::
* clear::
* close::
* directory::
* edit::
* exit::
* file::
* help::
* load::
* log::
* parse::
* quit::
* save::
* set::
* show::
* status::
* system::
* take::
@end menu

@c ----------------------------------------------------------------------------
@node cd, clear, Interactive commands, Interactive commands
@subsection cd

@w{@code{cd} @var{directory}}
changes the current directory to the one specified.  Spaces in the
directory pathname are not permitted.

For MS-DOS or Windows, you can give a full path starting with the disk
letter and a colon (for example, @code{a:}); a path starting with
@code{\} which indicates a directory at the top level of the current
disk; a path starting with @code{..} which indicates the directory
above the current one; and so on.  Directories are separated by the
@code{\} character.  (The forward slash @code{/} works just as well as
the backslash @code{\} for MS-DOS or Windows.)

For the Macintosh, you can give a full path starting with the name of
a hard disk, a path starting with @code{:} which means the current
folder, or one starting @code{::} which means the folder containing the
current one (and so on).

For Unix, you can give a full path starting with a @code{/} (for
example, @code{/usr/pcpatr}); a path starting with @code{..} which
indicates the directory above the current one; and so on.  Directories
are separated by the @code{/} character.

@c ----------------------------------------------------------------------------
@node clear, close, cd, Interactive commands
@subsection clear

@code{clear} erases all existing grammar and lexicon information,
allowing the user to prepare to load information for a new language.
Strictly speaking, it is not needed since the @w{@code{load grammar}}
command erases the previously existing grammar, and the
@w{@code{load lexicon}} and @w{@code{load analysis}} commands erase any
previously existing lexicon.

@c ----------------------------------------------------------------------------
@node close, directory, clear, Interactive commands
@subsection close

@code{close}
closes the current log file opened by a previous @code{log} command.

@c ----------------------------------------------------------------------------
@node directory, edit, close, Interactive commands
@subsection directory

@code{directory}
lists the contents of the current directory.  This command is available
only for the MS-DOS and Unix implementations.  It does not exist for
Microsoft Windows or the Macintosh.

@c ----------------------------------------------------------------------------
@node edit, exit, directory, Interactive commands
@subsection edit

@w{@code{edit} @var{filename}}
attempts to edit the specified file using the program indicated by the
environment variable @code{EDITOR}.  If this environment variable is not
defined, then @code{edlin} is used to edit the file on MS-DOS, and
@code{vi} is used to edit the file on Unix.  (These defaults should
convince you to set this variable!)  This command is not available for
Microsoft Windows or the Macintosh.

@c ----------------------------------------------------------------------------
@node exit, file, edit, Interactive commands
@subsection exit

@code{exit}
stops PC-PATR, returning control to the operating system.  This is the
same as @code{quit}.

@c ----------------------------------------------------------------------------
@node file, help, exit, Interactive commands
@subsection file

The @code{file} commands process data from a file, optionally writing
the parse results to another file.  Each of these commands is described
below.

@menu
* file disambiguate::
* file parse::
@end menu

@c ----------------------------------------------------------------------------
@node file disambiguate, file parse, file, file
@subsubsection file disambiguate

@w{@code{file disambiguate} @var{input.ana} @var{[out.ana]}}
reads sentences from the specified AMPLE analysis file and writes the
corresponding parse trees and feature structures either to the screen
or to the optionally specified output file.  If the output file is
written, ambiguous word parses are eliminated as much as possible as a
result of the sentence parsing.  When finished, a statistical report of
successful (sentence) parses is displayed on the screen.

@c ----------------------------------------------------------------------------
@node file parse, , file disambiguate, file
@subsubsection file parse

@w{@code{file parse} @var{input-file} @var{[output-file]}}
reads sentences from the specified input file, one per line, and writes
the corresponding parse trees and feature structures to the screen or
to the optionally specified output file.  The comment character is in
effect while reading this file.  PC-PATR currently makes no attempt to
handle either capitalization or punctuation.  @sc{probably some
capability for handling punctuation will be added at some point.}

This command behaves the same as @code{parse} except that input comes
from a file rather than the keyboard, and output may go to a file
rather than the screen.  When finished, a statistical report of
successful parses is displayed on the screen.

@c ----------------------------------------------------------------------------
@node help, load, file, Interactive commands
@subsection help

@w{@code{help} @var{command}}
displays a description of the specified command.  If @code{help} is typed
by itself, PC-PATR displays a list of commands with short descriptions of
each command.

@c ----------------------------------------------------------------------------
@node load, log, help, Interactive commands
@subsection load

The @code{load} commands all load information stored in specially
formatted files.  The @w{@code{load ample}} and @w{@code{load kimmo}}
commands activate morphological parsers, and serve as alternatives to
@w{@code{load lexicon}} (or @w{@code{load analysis}}) for obtaining the
category and other feature information for words.  Each of the
@code{load} commands is described below.

@menu
* load ample control::
* load ample dictionary::
* load ample text-control::
* load analysis::
* load grammar::
* load kimmo grammar::
* load kimmo lexicon::
* load kimmo rules::
* load lexicon::
@end menu

@c ----------------------------------------------------------------------------
@node load ample control, load ample dictionary, load, load
@subsubsection load ample control

@w{@code{load ample control} @var{xxad01.ctl} @var{xxancd.tab} @var{[xxordc.tab]}}
erases any existing AMPLE information (including dictionaries) and
reads control information from the specified files.  This also erases
any stored PC-Kimmo information.

At least two and possibly three files are loaded by this command.  The
first file is the AMPLE @var{analysis data} file.  It has a
default filetype extension of @code{.ctl} but no default filename.  The
second file is the AMPLE dictionary code table file.  It has a
default filetype extension of @code{.tab} but no default filename.  The
third file is an optional dictionary orthography change table.  It has a
default filetype extension of @code{.tab} and no default filename.

@w{@code{l am c}} is a synonym for @w{@code{load ample control}}.

@c ----------------------------------------------------------------------------
@node load ample dictionary, load ample text-control, load ample control, load
@subsubsection load ample dictionary

@w{@code{load ample dictionary} @var{[prefix.dic] [infix.dic] [suffix.dic] root1.dic [@dots{}]}}
or@*
@w{@code{load ample dictionary} @var{file01.dic [file02.dic @dots{}]}}
erases any existing AMPLE dictionary information and reads the
specified files.  This also erases any stored PC-Kimmo information.

The first form of the command is for using a dictionary whose files are
divided according to morpheme type (@w{@code{set ample-dictionary split}}).
The different types of dictionary files must be loaded
in the order shown, with any unneeded affix dictionaries omitted.

The second form of the command is for using a dictionary whose entries
contain the type of morpheme
(@w{@code{set ample-dictionary unified}}).@footnote{This is a new feature
of AMPLE version 3.}

@w{@code{l am d}} is a synonym for @w{@code{load ample dictionary}}.

@c ----------------------------------------------------------------------------
@node load ample text-control, load analysis, load ample dictionary, load
@subsubsection load ample text-control

@w{@code{load ample text-control} @var{xxintx.ctl}}
erases any existing AMPLE text input control information and reads
the specified file.  This also erases any stored PC-Kimmo information.

The text input control file has a default filetype extension of
@code{.ctl} but no default filename.

@w{@code{l am t}} is a synonym for @w{@code{load ample text-control}}.

@c ----------------------------------------------------------------------------
@node load analysis, load grammar, load ample text-control, load
@subsubsection load analysis

@w{@code{load analysis} @var{file1.ana} @var{[file2.ana @dots{}]}}
erases any existing lexicon and reads a new lexicon from the specified
AMPLE analysis file(s).  Note that more than one file may be loaded
with the single @w{@code{load analysis}} command: duplicate entries are not
stored in the lexicon.

The default filetype extension for @w{@code{load analysis}} is @code{.ana},
and the default filename is @code{ample.ana}.

@w{@code{l a}} is a synonym for @w{@code{load analysis}}.

@c ----------------------------------------------------------------------------
@node load grammar, load kimmo grammar, load analysis, load
@subsubsection load grammar

@w{@code{load grammar} @var{file.grm}}
erases any existing grammar and reads a new grammar from the specified file.

The default filetype extension for @w{@code{load grammar}} is @code{.grm},
and the default filename is @code{grammar.grm}.

@w{@code{l g}} is a synonym for @w{@code{load grammar}}.

@c ----------------------------------------------------------------------------
@node load kimmo grammar, load kimmo lexicon, load grammar, load
@subsubsection load kimmo grammar

@w{@code{load kimmo grammar} @var{file.grm}}
erases any existing PC-Kimmo (word) grammar and reads a new word grammar
from the specified file.

The default filetype extension for @w{@code{load kimmo grammar}} is
@code{.grm}, and the default filename is @code{grammar.grm}.

@w{@code{l k g}} is a synonym for @w{@code{load kimmo grammar}}.

@c ----------------------------------------------------------------------------
@node load kimmo lexicon, load kimmo rules, load kimmo grammar, load
@subsubsection load kimmo lexicon

@w{@code{load kimmo lexicon} @var{file.lex}}
erases any existing PC-Kimmo lexicon information and reads a new
morpheme lexicon from the specified file.  A PC-Kimmo rules file must
be loaded before a PC-Kimmo lexicon file can be loaded.

The default filetype extension for @w{@code{load kimmo lexicon}} is
@code{.lex}, and the default filename is @code{lexicon.lex}.

@w{@code{l k l}} is a synonym for @w{@code{load kimmo lexicon}}.

@c ----------------------------------------------------------------------------
@node load kimmo rules, load lexicon, load kimmo lexicon, load
@subsubsection load kimmo rules

@w{@code{load kimmo rules} @var{file.rul}}
erases any existing PC-Kimmo rules and reads a
new set of rules from the specified file.  This also erases any stored
AMPLE information.

The default filetype extension for @w{@code{load kimmo rules}} is
@code{.rul}, and the default filename is @code{rules.rul}.

@w{@code{l k r}} is a synonym for @w{@code{load kimmo rules}}.

@c ----------------------------------------------------------------------------
@node load lexicon, , load kimmo rules, load
@subsubsection load lexicon

@w{@code{load lexicon} @var{file1.lex} @var{[file2.lex @dots{}]}}
erases any existing lexicon and reads a new lexicon from the specified
file(s).  Note that more than one file may be loaded with a single
@w{@code{load lexicon}} command.

The default filetype extension for @w{@code{load lexicon}} is @code{.lex},
and the default filename is @code{lexicon.lex}.

@w{@code{l l}} is a synonym for @w{@code{load lexicon}}.

@c ----------------------------------------------------------------------------
@node log, parse, load, Interactive commands
@subsection log

@w{@code{log} @var{[file.log]}}
opens a log file.  Each item processed by a @code{parse} command
is stored to the log file as well as being displayed on the screen.

If a filename is given on the same line as the @code{log} command, then
that file is used for the log file.  Any previously existing file with
the same name will be overwritten.  If no filename is provided, then
the file @code{pcpatr.log} in the current directory is used for the log
file.

Use @code{close} to stop recording in a log file.  If a @code{log}
command is given when a log file is already open, then the earlier log
file is closed before the new log file is opened.

@c ----------------------------------------------------------------------------
@node parse, quit, log, Interactive commands
@subsection parse

@w{@code{parse} @var{[sentence or phrase]}}
attempts to parse the input sentence according to the loaded grammar.
If a sentence is typed on the same line as the command, then that
sentence is parsed.  If the @code{parse} command is given by itself,
then the user is prompted repeatedly for sentences to parse.  This
cycle of typing and parsing is terminated by typing an empty
``sentence'' (that is, nothing but the @code{Enter} or @code{Return}
key).

Both the grammar and the lexicon must be loaded before using this
command.

@c ----------------------------------------------------------------------------
@node quit, save, parse, Interactive commands
@subsection quit

@code{quit}
stops PC-PATR, returning control to the operating system.  This is the
same as @code{exit}.

@c ----------------------------------------------------------------------------
@node save, set, quit, Interactive commands
@subsection save

The @code{save} commands write information stored in memory to a file
suitable for reloading into PC-PATR later.  Each of these commands is
described below.

@menu
* save lexicon::
* save status::
@end menu

@c ----------------------------------------------------------------------------
@node save lexicon, save status, save, save
@subsubsection save lexicon

@w{@code{save lexicon} @var{[file.lex]}}
writes the current lexicon contents to the designated file.  The output
lexicon file must be specified.  This can be useful if you are using a
morphological parser to populate the lexicon.

@c ----------------------------------------------------------------------------
@node save status, , save lexicon, save
@subsubsection save status

@w{@code{save status} @var{[file.tak]}}
writes the current settings to the designated file in the form of
PC-PATR commands.  If the file is not specified, the settings are
written to @code{pcpatr.tak} in the current directory.

@c ----------------------------------------------------------------------------
@node set, show, save, Interactive commands
@subsection set

The @code{set} commands control program behavior by setting internal
program variables.  Each of these commands (and variables) is described
below.

@menu
* set ambiguities::
* set ample-dictionary::
* set check-cycles::
* set comment::
* set failures::
* set features::
* set final-punctuation::
* set gloss::
* set kimmo check-cycles::
* set kimmo promote-defaults::
* set kimmo top-down-filter::
* set limit::
* set marker category::
* set marker features::
* set marker gloss::
* set marker record::
* set marker rootgloss::
* set marker word::
* set promote-defaults::
* set property-is-feature::
* set recognize-only::
* set rootgloss::
* set timing::
* set top-down-filter::
* set tree::
* set trim-empty-features::
* set unification::
* set verbose::
* set warnings::
* set write-ample-parses::
@end menu

@c ----------------------------------------------------------------------------
@node set ambiguities, set ample-dictionary, set, set
@subsubsection set ambiguities

@w{@code{set ambiguities} @var{number}}
limits the number of analyses printed to the given number.  The default
value is 10.  Note that this does not limit the number of analyses
produced, just the number printed.

@c ----------------------------------------------------------------------------
@node set ample-dictionary, set check-cycles, set ambiguities, set
@subsubsection set ample-dictionary

@w{@code{set ample-dictionary} @var{value}}
determines whether or not the AMPLE dictionary files are divided
according to morpheme type.  @w{@code{set ample-dictionary split}} declares
that the AMPLE dictionary is divided into a
prefix dictionary file, an infix dictionary file, a suffix dictionary
file, and one or more root dictionary files.  The existence of the
three affix dictionary depends on settings in the AMPLE analysis
data file.  If they exist, the @w{@code{load ample dictionary}} command
requires that they be given in this relative
order: prefix, infix, suffix, root(s).

@w{@code{set ample-dictionary unified}} declares that any of the AMPLE
dictionary files may contain any type of morpheme.  This implies that
each dictionary entry may contain a field specifying the type of
morpheme (the default is @var{root}), and that the dictionary code
table contains a @code{\unified} field.  One of the changes
listed under @code{\unified} must convert a backslash code to @code{T}.

The default is for the AMPLE dictionary to be
@emph{split}.@footnote{The unified dictionary is a new feature of AMPLE
version 3.}

@c ----------------------------------------------------------------------------
@node set check-cycles, set comment, set ample-dictionary, set
@subsubsection set check-cycles

@w{@code{set check-cycles} @var{value}}
enables or disables a check to prevent cycles in the parse chart.
@w{@code{set check-cycles on}} turns on this check, and
@w{@code{set check-cycles off}} turns it off.  This check
slows down the parsing of a sentence, but it makes the parser less
vulnerable to hanging on perverse grammars.  The default setting is
@code{on}.

@c ----------------------------------------------------------------------------
@node set comment, set failures, set check-cycles, set
@subsubsection set comment

@w{@code{set comment} @var{character}}
sets the comment character to the indicated value.  If @var{character}
is missing (or equal to the current comment character), then comment
handling is disabled.  The default comment character is @code{;}
(semicolon).

@c ----------------------------------------------------------------------------
@node set failures, set features, set comment, set
@subsubsection set failures

@w{@code{set failures} @var{value}}
enables or disables @var{grammar failure mode}.  @w{@code{set failures on}}
turns on grammar failure mode, and @w{@code{set failures off}} turns it
off.  When grammar failure mode is on, the partial results of forms
that fail the grammar module are displayed.  A form may fail the
grammar either by failing the feature constraints or by failing the
constituent structure rules. In the latter case, a partial tree (bush)
will be returned.  The default setting is @code{off}.

Be careful with this option.  Setting failures to @code{on} can cause
the PC-PATR to go into an infinite loop for certain recursive grammars
and certain input sentences.  @sc{we may try to do something to detect
this type of behavior, at least partially.}

@c ----------------------------------------------------------------------------
@node set features, set final-punctuation, set failures, set
@subsubsection set features

@w{@code{set features} @var{value}}
determines how features will be displayed.

@w{@code{set features all}} enables the display of the features for all
nodes of the parse tree.

@w{@code{set features top}} enables the display of the feature
structure for only the top node of the parse tree.  This is the default
setting.

@w{@code{set features flat}} causes features to be displayed in a flat,
linear string that uses less space on the screen.

@w{@code{set features full}} causes features to be displayed in an
indented form that makes the embedded structure of the feature set
clear.  This is the default setting.

@w{@code{set features on}} turns on features display mode, allowing
features to be shown.  This is the default setting.

@w{@code{set features off}} turns off features display mode, preventing
features from being shown.

@c ----------------------------------------------------------------------------
@node set final-punctuation, set gloss, set features, set
@subsubsection set final-punctuation

@w{@code{set final-punctuation} @var{value}}
defines the set of characters used to mark the ends of sentences.  The
individual characters must be separated by spaces so that digraphs and
trigraphs can be used, not just single character units.  The default is
@w{@code{. ! ? : ;}}.

This variable setting affects only the @w{@code{file disambiguate}} command.

@c ----------------------------------------------------------------------------
@node set gloss, set kimmo check-cycles, set final-punctuation, set
@subsubsection set gloss

@w{@code{set gloss} @var{value}}
enables the display of glosses in the parse tree output if @var{value} is
@code{on}, and disables the display of glosses if @var{value} is
@code{off}.  If any glosses exist in the lexicon file, then @code{gloss} is
automatically turned @code{on} when the lexicon is loaded.  If no glosses
exist in the lexicon, then this flag is ignored.

@c ----------------------------------------------------------------------------
@node set kimmo check-cycles, set kimmo promote-defaults, set gloss, set
@subsubsection set kimmo check-cycles

@w{@code{set kimmo check-cycles} @var{value}}
enables or disables a check to prevent cycles in a word parse chart
created by the embedded PC-Kimmo morphological parser.
@w{@code{set kimmo check-cycles on}} turns on this check, and
@w{@code{set kimmo check-cycles off}} turns it off.  This check slows
down the parsing of a sentence, but it makes the parser less vulnerable
to hanging on perverse grammars.  The default setting is @code{on}.

@c ----------------------------------------------------------------------------
@node set kimmo promote-defaults, set kimmo top-down-filter, set kimmo check-cycles, set
@subsubsection set kimmo promote-defaults

@w{@code{set kimmo promote-default} @var{value}}
controls whether default atomic values in the feature structures loaded
from the lexicon are ``promoted'' to ordinary atomic values before
parsing a word with the embedded PC-Kimmo morphological parser.
@w{@code{set kimmo promote-defaults on}} turns on this behavior, and
@w{@code{set kimmo promote-defaults off}} turns it off.  The default
setting is @code{on}.  (It is arguable that this is the wrong choice for
the default, but this has been the behavior since the program was first
written.)

@c ----------------------------------------------------------------------------
@node set kimmo top-down-filter, set limit, set kimmo promote-defaults, set
@subsubsection set kimmo top-down-filter

@w{@code{set kimmo top-down-filter} @var{value}}
enables or disables top-down filtering in the embedded PC-Kimmo
morphological parser, based on the morpheme categories.
@w{@code{set kimmo top-down-filter on}} turns on this filtering, and
@w{@code{set kimmo top-down-filter off}} turns it off.  The top-down
filter speeds up the parsing of a sentence, but might cause the parser to
miss some valid parses.  The default setting is @code{on}.

This should not be required in the final version of PC-PATR.

@c ----------------------------------------------------------------------------
@node set limit, set marker category, set kimmo top-down-filter, set
@subsubsection set limit
@w{@code{set limit} @var{number}}
sets the time limit (in seconds) for parsing a sentence.  Its argument is
a number greater than or equal to zero, which is the maximum number of
seconds than a parse is allowed before being cancelled.  The default
value is @code{0}, which has the special meaning that no time limit is
imposed.

NOTE: this feature is new and still somewhat experimental.  It may not be
fully debugged, and may cause unforeseen side effects such as program
crashes some time after one or more parses are cancelled due to exceeding
the set time limit.

@c ----------------------------------------------------------------------------
@node set marker category, set marker features, set limit, set
@subsubsection set marker category

@w{@code{set marker category} @var{marker}}
establishes the marker for the field containing the category (part of
speech) feature.  The default is @code{\c}.

@c ----------------------------------------------------------------------------
@node set marker features, set marker gloss, set marker category, set
@subsubsection set marker features

@w{@code{set marker features} @var{marker}}
establishes the marker for the field containing miscellaneous features.
(This field is not needed for many words.)  The default is @code{\f}.

@c ----------------------------------------------------------------------------
@node set marker gloss, set marker record, set marker features, set
@subsubsection set marker gloss

@w{@code{set marker gloss} @var{marker}}
establishes the marker for the field containing the word gloss.  The
default is @code{\g}.

@c ----------------------------------------------------------------------------
@node set marker record, set marker rootgloss, set marker gloss, set
@subsubsection set marker record

@w{@code{set marker record} @var{marker}}
establishes the field marker that begins a new record in the lexicon
file.  This may or may not be the same as the @code{word} marker.  The
default is @code{\w}.

@c ----------------------------------------------------------------------------
@node set marker rootgloss, set marker word, set marker record, set
@subsubsection set marker rootgloss

@w{@code{set marker rootgloss} @var{marker}}
establishes the marker for the field containing the word rootgloss.  The
default is @code{\r}.  The word's root gloss may be useful for handling
syntactic constructions such as verb reduplication.  One can write a
unification constraint that ensures that the rootgloss unifies between
two successive lexical items/terminal symbols.  Note that this does
not work when using Kimmo to parse words.

@c ----------------------------------------------------------------------------
@node set marker word, set promote-defaults, set marker rootgloss, set
@subsubsection set marker word

@w{@code{set marker word} @var{marker}}
establishes the marker for the word field.  The default is @code{\w}.

@c ----------------------------------------------------------------------------
@node set promote-defaults, set property-is-feature, set marker word, set
@subsubsection set promote-defaults

@w{@code{set promote-defaults} @var{value}} controls whether default
atomic values in the feature structures loaded from the lexicon are
``promoted'' to ordinary atomic values before parsing a sentence.
@w{@code{set promote-defaults on}} turns on this behavior, and
@w{@code{set promote-defaults off}} turns it off.  (This can affect
feature unification since a conflicting default value does not cause a
failure: the default value merely disappears.)  The default setting is
@code{on}.  (It is arguable that this is the wrong choice for the
default, but this has been the behavior since the program was first
written.)

@c ----------------------------------------------------------------------------
@node set property-is-feature, set recognize-only, set promote-defaults, set
@subsubsection set property-is-feature

@w{@code{set property-is-feature} @var{value}} controls whether the
values in the AMPLE analysis @code{\p} (property) field are to be
interpreted as feature template names, the same as the values in the AMPLE
analysis @code{\fd} (feature descriptor) field.
@w{@code{set property-is-feature on}} turns on this behavior, and
@w{@code{set property-is-feature off}} turns it off.
The default setting is @code{off}.  (It is arguable that this is the
wrong choice for the default, but this has been the behavior since the
program was first written.)

@c ----------------------------------------------------------------------------
@node set recognize-only, set rootgloss, set property-is-feature, set
@subsubsection set recognize-only

@w{@code{set recognize-only} @var{value}} controls whether the parser
acts as a recognizer or as a real parser and thus produces all
possible parses.

@w{@code{set recognize-only on}} causes the first successful parse to terminate the parsing process.

@w{@code{set recognize-only off}} allows all possible parses to be to be checked and returned by the parsing process.

The default setting is @code{off}.

@c ----------------------------------------------------------------------------
@node set rootgloss, set timing, set recognize-only, set
@subsubsection set rootgloss

@w{@code{set rootgloss} @var{value}} specifies if root glosses should be
treated as a lexical feature and, if so, which root(s) in compound roots
are used.  The word's root gloss may be useful for handling syntactic
constructions such as verb reduplication.  Note that this does not work
when using Kimmo to parse words.

@w{@code{set rootgloss off}} turns off the use of the root gloss feature.
This is the default setting.

@w{@code{set rootgloss on}} turns on the use of the root gloss feature.
This value should be used when using a word lexicon (i.e. when using the
@code{load lexicon file} command).  N.B. that it must be set @b{before} one
loads the lexicon file (otherwise, no root glosses will be loaded).

@w{@code{set rootgloss leftheaded}} turns on the use of the root gloss
feature and, if one is either disambiguating an ANA file or using AMPLE to
parse the words in a sentence, only the leftmost root in compound roots
will be used as the root gloss feature value.

@w{@code{set rootgloss rightheaded}} turns on the use of the root gloss
feature and, if one is either disambiguating an ANA file or using AMPLE to
parse the words in a sentence, only the rightmost root in compound roots
will be used as the root gloss feature value.

@w{@code{set rootgloss all}} turns on the use of the root gloss
feature and, if one is either disambiguating an ANA file or using AMPLE to
parse the words in a sentence, every root gloss in compound roots
will be used as the root gloss feature value.

@c ----------------------------------------------------------------------------
@node set timing, set top-down-filter, set rootgloss, set
@subsubsection set timing

@w{@code{set timing} @var{value}}
enables timing mode if @var{value} is @code{on}, and disables timing
mode if @var{value} is @code{off}.  If timing mode is @code{on}, then
the elapsed time required to process a command is displayed when the
command finishes.  If timing mode is @code{off}, then the elapsed time
is not shown.  The default is @code{off}.  (This option is useful only
to satisfy idle curiosity.)

@c ----------------------------------------------------------------------------
@node set top-down-filter, set tree, set timing, set
@subsubsection set top-down-filter

@w{@code{set top-down-filter} @var{value}}
enables or disables top-down filtering based on the categories.
@w{@code{set top-down-filter on}} turns on this filtering,
and @w{@code{set top-down-filter off}} turns it off.  The
top-down filter speeds up the parsing of a sentence, but might cause
the parser to miss some valid parses.  The default setting is
@code{on}.

This should not be required in the final version of PC-PATR.

@c ----------------------------------------------------------------------------
@node set tree, set trim-empty-features, set top-down-filter, set
@subsubsection set tree

@w{@code{set tree} @var{value}}
specifies how parse trees should be displayed.

@w{@code{set tree full}} turns on the parse tree display, displaying the
result of the parse as a full tree.  This is the default setting.
A short sentence would look something like this:
@example

@group
   Sentence_1
		|
  Declarative_2
   _____|_____
 NP_3      VP_5
   |      ___|____
  N_4    V_6  COMP_7
 cows    eat     |
			   NP_8
				 |
				N_9
			   grass
@end group

@end example

@w{@code{set tree flat}} turns on the parse tree display, displaying the
result of the parse as a flat tree structure in the form of a bracketed
string.  The same short sentence would look something like this:
@example

@group
(Sentence_1 (Declarative_2 (NP_3 (N_4  cows))(VP_5 (V_6  eat)(COMP_7
		(NP_8 (N_9  grass))))))
@end group

@end example

@w{@code{set tree indented}} turns on the parse tree display, displaying
the result of the parse in an indented format sometimes called a
@emph{northwest tree}.  The same short sentence would look like this:
@example

@group
Sentence_1
	Declarative_2
		NP_3
			N_4  cows
		VP_5
			V_6  eat
			COMP_7
				NP_8
					N_9  grass
@end group

@end example

@w{@code{set tree xml}} turns on the parse tree display, displaying the
result of the parse in an XML format.  The same short sentence would look
like this:
@example

@group
<Analysis count="1">
  <Parse>
	<Node cat="Sentence" id="_1._1">
	  <Fs>
	  <F name="cat"><str>Sentence</str></f>
	  </Fs>
	  <Node cat="Declarative" id="_1._2">
		<Fs>
		<F name="cat"><str>Declarative</str></f>
		</Fs>
		<Node cat="NP" id="_1._3">
		  <Fs>
		  <F name="cat"><str>NP</str></f>
		  </Fs>
		  <Leaf cat="N" id="_1._4">
			<Fs>
			<F name="cat"><str>N</str></f>
			<F name="lex"><str>cows</str></f>
			</Fs>
			<Lexfs>
			<F name="cat"><str>N</str></f>
			<F name="lex"><str>cows</str></f>
			</Lexfs>
			<Str>cows</str>
		  </Leaf>
		</Node>
		<Node cat="VP" id="_1._5">
		  ...                   (35 lines omitted)
		</Node>
	  </Node>
	</Node>
  </Parse>
</Analysis>
@end group

@end example

@w{@code{set tree off}} disables the display of parse trees altogether.

@c ----------------------------------------------------------------------------
@node set trim-empty-features, set unification, set tree, set
@subsubsection set trim-empty-features

@w{@code{set trim-empty-features} @var{value}}
disables the display of empty feature values if @var{value} is
@code{on}, and enables the display of empty feature values if
@var{value} is @code{off}.  The default is not to display empty feature
values.

@c ----------------------------------------------------------------------------
@node set unification, set verbose, set trim-empty-features, set
@subsubsection set unification

@w{@code{set unification} @var{value}}
enables or disables feature unification.
@w{@code{set unification on}} turns on unification mode.  This is the
default setting.

@w{@code{set unification off}} turns off feature unification in the
grammar.  Only the context-free phrase structure rules are used to
guide the parse; the feature contraints are ignored.  This can be
dangerous, as it is easy to introduce infinite cycles in recursive
phrase structure rules.

@c ----------------------------------------------------------------------------
@node set verbose, set warnings, set unification, set
@subsubsection set verbose

@w{@code{set verbose} @var{value}}
enables or disables the screen display of parse trees in the
@w{@code{file parse}}
command.  @w{@code{set verbose on}} enables the screen display of parse
trees, and @w{@code{set verbose off}} disables such display.  The default
setting is @code{off}.

@c ----------------------------------------------------------------------------
@node set warnings, set write-ample-parses, set verbose, set
@subsubsection set warnings

@w{@code{set warnings} @var{value}}
enables warning mode if @var{value} is @code{on}, and disables
warning mode if @var{value} is @code{off}.  If warning mode is
enabled, then warning messages are displayed on the output. If warning
mode is disabled, then no warning messages are displayed.  The default
setting is @code{on}.

@c ----------------------------------------------------------------------------
@node set write-ample-parses, , set warnings, set
@subsubsection set write-ample-parses

@w{@code{set write-ample-parses} @var{value}}
enables writing @code{\parse} and @code{\features} fields at the end of
each sentence in the disambiguated analysis file if @var{value} is
@code{on}, and disables writing these fields if @var{value} is
@code{off}.  The default setting is @code{off}.

This variable setting affects only the @w{@code{file disambiguate}} command.

@c ----------------------------------------------------------------------------
@node show, status, set, Interactive commands
@subsection show

The @code{show} commands display internal settings on the screen.  Each
of these commands is described below.

@menu
* show lexicon::
* show status::
@end menu

@c ----------------------------------------------------------------------------
@node show lexicon, show status, show, show
@subsubsection show lexicon

@w{@code{show lexicon}}
prints the contents of the lexicon stored in memory on the standard
output.  @sc{this is not very useful, and may be removed.}

@c ----------------------------------------------------------------------------
@node show status, , show lexicon, show
@subsubsection show status

@w{@code{show status}}
displays the names of the current grammar, sentences, and log files,
and the values of the switches established by the @code{set} command.

@code{show} (by itself) and @code{status} are synonyms for
@w{@code{show status}}.

@c ----------------------------------------------------------------------------
@node status, system, show, Interactive commands
@subsection status

@code{status}
displays the names of the current grammar, sentences, and log files,
and the values of the switches established by the @code{set} command.

@c ----------------------------------------------------------------------------
@node system, take, status, Interactive commands
@subsection system

@w{@code{system} @var{[command]}}
allows the user to execute an operating system command (such as
checking the available space on a disk) from within PC-PATR.  This is
available only for MS-DOS and Unix, not for Microsoft Windows or the
Macintosh.


If no system-level command is given on the line with the @code{system}
command, then PC-PATR is pushed into the background and a new system
command processor (shell) is started.  Control is usually returned to
PC-PATR in this case by typing @code{exit} as the operating system
command.

@code{!} (exclamation point) is a synonym for @code{system}.

@c ----------------------------------------------------------------------------
@node take, , system, Interactive commands
@subsection take

@w{@code{take} @var{[file.tak]}}
redirects command input to the specified file.

The default filetype extension for @code{take} is @code{.tak}, and the default
filename is @code{pcpatr.tak}.

@code{take} files can be nested three deep.  That is, the user types
@w{@code{take file1}}, @code{file1} contains the command @w{@code{take file2}},
and @code{file2} has the command @w{@code{take file3}}.  It would be an
error for @code{file3} to contain a @code{take} command.  This should
not prove to be a serious limitation.

A @code{take} file can also be specified by using the @code{-t} command
line option when starting PC-PATR.  When started, PC-PATR looks for a
@code{take} file named @file{pcpatr.tak} in the current directory to
initialize itself with.

@c ----------------------------------------------------------------------------
@node Grammar file, Standard format, Running PC-PATR, Top
@chapter The PC-PATR Grammar File

The following specifications apply generally to the grammar file:

@itemize @bullet
@item
Blank lines, spaces, and tabs separate elements of the grammar file from one
another, but are ignored otherwise.
@item
The comment character declared by the @w{@code{set comment}} command
@ifset txt
(see `set comment' above)
@end ifset
@ifclear txt
(@pxref{set comment})
@end ifclear
is operative in the grammar file.  The default
comment character is the semicolon (@code{;}).  Comments may be placed
anywhere in the grammar file.  Everything following a comment character
to the end of the line is ignored.
@item
A grammar file is divided into fields identified by a small set of keywords.

@enumerate
@item
@code{Rule} starts a context-free phrase structure rule with its
set of feature constraints.  These rules define how words join together
to form phrases, clauses, or sentences.  The lexicon and grammar are
tied together by using the lexical categories as the terminal symbols
of the phrase structure rules and by using the other lexical features
in the feature constraints.
@item
@code{Let} starts a feature template definition.  Feature
templates are used as macros (abbreviations) in the lexicon.  They may
also be used to assign default feature structures to the categories.
@item
@code{Parameter} starts a program parameter definition.  These
parameters control various aspects of the program.
@item
@code{Define} starts a lexical rule definition.  As noted in Shieber
(1985), something more powerful than just abbreviations for common
feature elements is sometimes needed to represent systematic
relationships among the elements of a lexicon.  This need is met by
lexical rules, which express transformations rather than mere
abbreviations.  Lexical rules serve two primary purposes in PC-PATR:
modifying the feature structures associated with lexicon entries to
produce additional lexicon entries, and modifying the feature structures
produced by a morphological parser to fit the syntactic grammar
description.
@item
@code{Constraint} starts a constraint template definition.  Constraint
templates are used as macros (abbreviations) in the grammar file.
@item
@code{Lexicon} starts a lexicon section.  This is only for
compatibility with the original PATR-II.  The section name is
skipped over properly, but nothing is done with it.
@item
@code{Word} starts an entry in the lexicon.  This is only for
compatibility with the original PATR-II.  The entry is skipped
over properly, but nothing is done with it.@footnote{Would this be a
useful enhancement to PC-PATR?}
@item
@code{End} effectively terminates the file.  Anything following this
keyword is ignored.
@item
@code{Comment} starts a comment field.  The rest of the line following
the keyword is skipped over, and everything in following lines until the
next keyword is also ignored.  If you must use a keyword (other than
@code{comment} verbatim in one of the extra lines of a comment, put a
comment character at the beginning of the line containing the keyword.
@end enumerate
@noindent
Note that these keywords are not case sensitive:  @code{RULE} is the
same as @code{rule}, and both are the same as @code{Rule}.  Also, in
order to facilitate interaction with the @file{Shoebox} program, any
of the keywords may begin with a backslash @code{\} character.  For
example, @code{\Rule} and @code{\rule} are both acceptable alternatives
to @code{RULE} or @code{rule}.  The abbreviated form @code{\co} is a
special synonym for @code{comment} or @code{\comment}.  Note that there
is no requirement that these keywords appear at the beginning of a line.
@item
Except for @code{comment}, each of the fields in the grammar file may
optionally end with a period.  If there is no period, the next keyword
(in an appropriate slot) marks the end of one field and the beginning of
the next.
@end itemize

@menu
* Rules::                  Rule @dots{}
* Feature templates::      Let <name> be @dots{}
* Parameter settings::     Parameter <name> is @dots{}
* Lexical rules::          Define <name> as @dots{}
* Constraint templates::   Constraint <name> is @dots{}
@end menu

@c ----------------------------------------------------------------------------
@node Rules, Feature templates, Grammar file, Grammar file
@section Rules

A PC-PATR grammar rule has these parts, in the order listed:

@enumerate
@item the keyword @code{Rule}
@item an optional rule identifier enclosed in braces (@code{@{@}})
@item a phrase structure rule consisting of the following:

@enumerate a
@item the nonterminal symbol to be expanded
@item an arrow (@code{->}) or equal sign (@code{=})
@item zero or more terminal or nonterminal symbols, possibly marked for
alternation or optionality
@end enumerate
@item an optional colon (@code{:})
@item zero or more unification constraints
@item zero or more priority union operations
@item zero or more logical constraint operations
@item an optional period (@code{.})
@end enumerate

The optional rule identifier consists of one or more words enclosed in
braces.  Its current utility is only as a special form of comment
describing the intent of the rule.  (Eventually it may be used as a tag
for interactively adding and removing rules.)  The only limits on the
rule identifier are that it not contain the comment character and that
it all appears on the same line in the grammar file.

The terminal and nonterminal symbols in the rule have the following
characteristics:

@itemize @bullet
@item
Upper and lower case letters used in symbols are considered different.
For example, @code{NOUN} is not the same as @code{Noun}, and neither is
the same as @code{noun}.
@item
The symbol @code{X} (capital letter x) may be used to stand for any
terminal or nonterminal.  For example, this rule says that any category
in the grammar rules can be replaced by two copies of the same category
separated by a CJ.
@example

@group
Rule X -> X_1 CJ X_2
		<X cat>  = <X_1 cat>
		<X cat>  = <X_2 cat>
		<X arg1> = <X_1 arg1>
		<X arg1> = <X_2 arg1>
@end group

@end example
@noindent
The symbol X can be useful for capturing generalities.  Care must be
taken, since it can be replaced by anything.
@item
Index numbers are used to distinguish instances of a symbol that
is used more than once in a rule.  They are added to the end of a
symbol following an underscore character (@code{_}).  This is
illustrated in the rule for X above.
@item
The characters @code{()@{@}[]<>=:/} cannot be used in terminal or
nonterminal symbols since they are used for special purposes in the
grammar file.  The character @code{_} can be used @emph{only} for
attaching an index number to a symbol.
@item
By default, the left hand symbol of the first rule in the grammar file
is the start symbol of the grammar.
@end itemize

The symbols on the right hand side of a phrase structure rule may be
marked or grouped in various ways:

@itemize @bullet
@item
Parentheses around an element of the expansion (right hand) part of a
rule indicate that the element is optional. Parentheses may be placed
around multiple elements. This makes an optional group of elements.
@item
A forward slash (/) is used to separate alternative elements of the
expansion (right hand) part of a rule.
@item
Curly braces can be used for grouping alternative elements. For example the
following says that an S consists of an NP followed by either a TVP
or an IV:
@example

Rule S -> NP @{TVP / IV@}

@end example
@item
Alternatives are taken to be as long as possible. Thus if the curly
braces were omitted from the rule above, as in the rule below, the
TVP would be treated as part of the alternative containing the
NP. It would not be allowed before the IV.
@example

Rule S -> NP TVP / IV

@end example
@item
Parentheses group enclosed elements the same as curly braces
do.  Alternatives and groups delimited by parentheses or curly braces
may be nested to any depth.
@end itemize

The phrase structure rule can be followed by zero or more
@emph{unification constraints} that refer to symbols used in the rule.  A
unification constraint has these parts, in the order listed:

@enumerate
@item a feature path that begins with one of the symbols from the phrase
structure rule
@item an equal sign
@item either another path or a value
@end enumerate

A unification constraint that refers only to symbols on the right hand side
of the rule constrains their co-occurrence.  In the following rule and
constraint, the values of the @emph{agr} features for the NP and VP
nodes of the parse tree must unify:
@example

@group
Rule S -> NP VP
		<NP agr> = <VP agr>
@end group

@end example

If a unification constraint refers to a symbol on the right hand side of
the rule, and has an atomic value on its right hand side, then the
designated feature must not have a different value.  In the following
rule and constraint, the @emph{head case} feature for the NP node of
the parse tree must either be originally undefined or equal to NOM:
@example

@group
Rule S -> NP VP
		<NP head case> = NOM
@end group

@end example
@noindent
(After unification succeeds, the @emph{head case} feature for the NP
node of the parse tree will be equal to NOM.)

A unification constraint that refers to the symbol on the left hand side of
the rule passes information up the parse tree.  In the following rule
and constraint, the value of the @emph{tense} feature is passed from
the VP node up to the S node:
@example

@group
Rule S -> NP VP
		<S tense> = <VP tense>
@end group

@end example

@ifset txt
See `Feature constraints' above
@end ifset
@ifclear txt
@xref{Feature constraints},
@end ifclear
for more details about unification constraints.

The phrase structure rule can also be followed by zero or more
@emph{priority union operations} that refer to symbols used in the rule.  A
priority union operation has these parts, in the order listed:

@enumerate
@item a feature path that begins with one of the symbols from the phrase
structure rule
@item a priority union operation sign (@code{<=})
@item either another path or an atomic value
@end enumerate

Although priority union operations may be intermingled with unification
constraints following the phrase structure rule, they are applied only
after all unification constraints have succeeded.  Therefore, it makes
more sense to place them after all of the unification constraints as a
reminder of the order of application.

Priority union operations may not appear inside a disjunction: if two
rules logically differ only in the application of one priority union or
another, both rules must be written out in full.

The phrase structure rule can also be followed by zero or more
@emph{logical constraint operations} that refer to symbols used in the
rule.  A logical constraint operation has these parts, in the order
listed:
@enumerate
@item a feature path that begins with one of the symbols from the phrase
structure rule
@item a logical constraint operation sign (@code{==})
@item a logical constraint expression, or a constraint template label
@end enumerate
Although logical constraint operations may be intermingled with
unification constraints or priority union operations following the phrase
structure rule, they are applied only after all unification constraints
have succeeded and all priority union operations have been applied.
Therefore, it makes more sense to place them after all of the unification
constraints, and after any priority union operations, as a reminder of
the order of application.

Logical constraint operations may not appear inside a disjunction: if two
rules logically differ only in the application of one logical constraint or
another, both rules must be written out in full.

These last two elements of a PC-PATR rule are enhancements to the
original PATR-II formalism.  For this reason, they are discussed in more
detail in the following two sections.

@menu
* Priority union operations::
* Logical constraint operations::
@end menu

@c ----------------------------------------------------------------------------
@node Priority union operations, Logical constraint operations, Rules, Rules
@subsection Priority union operations

Unification is the only mechanism implemented in the original PATR-II
formulism for merging two feature structures.  There are situations where
the desired percolation of information is not easily expressed in terms
of unification.  For example, consider the following rule (where
@emph{ms} stands for @emph{morphosyntactic features}):
@example

@group
Stem -> Root Deriv:
		<Root ms>  =  <Deriv msFrom>
		<Stem ms>  =  <Root ms>
		<Stem ms>  =  <Deriv msTo>
@end group

@end example
@noindent
The first unification expression above imposes the agreement constraints
for this rule.  The second and third unification expressions attempt to
provide the percolation of information up to the @code{Stem}.  However,
it is quite possible for there to be a conflict between @code{<Root ms>}
and @code{<Deriv msTo>}.  Any such conflict would cause the third
unification expression to fail, causing the rule as a whole to fail.  The
only way around this at present is to provide a large number of
unification expressions that go into greater depth in the feature
structures.  Even then it may not be possible to always avoid conflicts.

An additional mechanism for merging feature structures is provided to
properly handle percolation of information: overwriting via priority union.
The notation of the previous example changes slightly to the following:
@example

@group
Stem -> Root Deriv:
		<Root ms>  =  <Deriv msFrom>
		<Stem ms>  =  <Root ms>
		<Stem ms> <=  <Deriv msTo>
@end group

@end example
@noindent
The only change is in the third expression under the rule: the
unification operator @code{=} has been changed to a priority union
operator @code{<=}.  This new operator is the same as unification except
for handling conflicts and storing results.  In unification, a conflict
causes the operation to fail.  In priority union, a conflict is resolved
by taking the value in the right hand feature structure.  In unification,
both the left hand feature structure and the right hand feature structure
are replaced by the unified result.  In priority union, only the left
hand feature structure is replaced by the result.

There is one other significant difference between unification and
priority union.  Unification is logically an unordered process; it makes
no difference what order the unification expressions are written.
Priority union, on the other hand, is inherently ordered; a priority
union operation always overrides any earlier priority union (or
unification) result.  For this reason, all unification expressions are
evaluated before any priority union expressions, and the ordering of the
priority union expressions is significant.

A BNF grammar for PC-PATR priority union operations follows.
@example

@group
<priority-union> ::= <feature-path> '<=' <feature-path>
				   | <feature-path> '<=' <ATOM>
@end group

<feature-path>   ::= '<' <label-list> '>'

@group
<label-list>     ::= <LABEL>
				   | <LABEL> <label-list>
@end group

@end example
@noindent
Note that both @code{<LABEL>} and @code{<ATOM>} refer to a single string
token of contiguous characters.

@c ----------------------------------------------------------------------------
@node Logical constraint operations, , Priority union operations, Rules
@subsection Logical constraint operations

Unification is the only mechanism implemented in the original PATR-II
formulism for imposing constraints on feature structures.  There are
situations where the desired constraint is not easily expressed in terms
of unification.  For example, consider the following rule:
@example

@group
Stem -> Root Deriv:
		<Root ms>  =  <Deriv msFrom>
		<Stem ms>  =  <Root ms>
		<Stem ms> <=  <Deriv msTo>
@end group

@end example
@noindent
where @code{<Root ms>} and @code{<Deriv msFrom>} have
the following feature structures:
@example

@group
[Root: [ms: [finite: - ...]]]

[Deriv: [msFrom: [tense: past ...]]]
@end group

@end example
@noindent
Assume that from our knowledge of verb morphology, we would like to rule out
this analysis because only finite verb roots (@code{[finite: +]}) are
marked for tense.  The only way to do this with unification is to add
@code{[finite: +]} to the @code{msFrom} feature of all the
tense bearing derivational suffixes.  This would work, but it adds
information to suffixes that properly belongs only to roots.  A better
approach would be some way to express the desired constraint more directly.
Consider the following rule:
@example

@group
Stem -> Root Deriv:
		<Root ms>  =  <Deriv msFrom>
		<Stem ms>  =  <Root ms>
		<Stem ms> <=  <Deriv msTo>
		<Stem ms> ==  [finite: +] <-> [tense: []]
@end group

@end example
@noindent
The fourth feature expression under the rule is a new operation called a
constraint.  This particular constraint is interpreted as follows: if the
feature structure @code{[finite: +]} @emph{subsumes} the feature
structure that is the value of @code{<Stem ms>}, then the feature
structure @code{[tense: []]} must also subsume the feature structure
that is the value of @code{<Stem ms>}, and if the feature
structure @code{[finite: +]} does not subsume the feature structure
that is the value of @code{<Stem ms>}, then the feature structure
@code{[tense: []]} must not subsume the feature structure that is the
value of @code{<Stem ms>}.  (A feature structure @emph{F1}
subsumes another feature structure @emph{F2} if @emph{F1} contains a
subset of the information contained by @emph{F2}.  The empty feature
structure @code{[]} subsumes all other feature structures.  Subsumption
is a partial ordering: not every two feature structures are in a subsumption
relation to each other.)

A constraint is much different both syntactically and semantically from
either unification or priority union.  The first difference is that a
constraint does not modify any feature structures; it merely compares the
content of two feature structures.  The second difference is that the right
hand side of a constraint expression is a logical expression involving one or
more feature structures rather than a feature path.

Constraints support two unary and four binary logical operations:
existence, negation, logical and, logical or, conditional, and
biconditional.  The following tables summarize these logical operations.
(@code{$} is used for the subsumption operation.  @code{*P} represents
the feature structure pointed to by the feature path associated with the
logical constraint.  @code{F}, @code{L}, and @code{R} represent a
feature structure associated with the logical constraint.)
@ifclear html
@ifinfo
@example

@group
		 existence negation
F $ *P    P == F    P == ~F
------    ------    -------
 true      true      false
 false     false     true
@end group

@group
				 logical and    logical or    conditional    biconditional
L $ *P  R $ *P    P == L & R    P == L / R    P == L -> R    P == L <-> R
------  ------    ----------    ----------    -----------    ------------
 true    true        true          true          true            true
 true    false       false         true          false           false
 false   true        false         true          true            false
 false   false       false         false         true            true
@end group

@end example
@end ifinfo
@iftex
@catcode`@&=4@catcode`@#=6

@smallskip
@hbox to @hsize{@hfill@vbox{@offinterlineskip@hrule
@halign{&@vrule#&@strut@enskip@hfil#@enskip@cr
height2pt&@omit&&@omit&&@omit&@cr
&&&existence@hfil&&negation@hfil&@cr
height2pt&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&@cr
&F @$ *P@hfil&&P == F@hfil&&P == ~F@hfil&@cr
height2pt&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&@cr
&true@hfil&&true@hfil&&false@hfil&@cr
height2pt&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&@cr
&false@hfil&&false@hfil&&true@hfil&@cr
height2pt&@omit&&@omit&&@omit&@cr
}
@hrule}@hfill}
@smallskip
@hbox to @hsize{@hfill@vbox{@offinterlineskip@hrule
@halign{&@vrule#&@strut@enskip@hfil#@enskip@cr
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
&&&&&logical and@hfil&&logical or@hfil&&conditional@hfil&&biconditional@hfil&@cr
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
&L @$ *P@hfil&&R @$ *P@hfil&&P == L @& R@hfil&&P == L / R@hfil&&P == L -> R@hfil&&P == L <-> R@hfil&@cr
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
&true@hfil&&true@hfil&&true@hfil&&true@hfil&&true@hfil&&true@hfil&@cr
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
&true@hfil&&false@hfil&&false@hfil&&true@hfil&&false@hfil&&false@hfil&@cr
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
&false@hfil&&true@hfil&&false@hfil&&true@hfil&&true@hfil&&false@hfil&@cr
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
@noalign{@hrule}
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr
&false@hfil&&false@hfil&&false@hfil&&false@hfil&&true@hfil&&true@hfil&@cr
height2pt&@omit&&@omit&&@omit&&@omit&&@omit&&@omit&@cr}
@hrule}@hfill}
@smallskip

@catcode`@#=12@catcode`@&=12
@end iftex
@end ifclear
@ifset html
@ifhtml
<table rules="all" frame="border" align="center">
<tbody>
<tr>
<th align="center"></th>
<th align="center">existence</th>
<th align="center">negation</th>
</tr>
<tr>
<th align="center">F $ *P</th>
<th align="center">P == F</th>
<th align="center">P == ~F</th>
</tr>
<tr>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">false</td>
</tr>
<tr>
<td align="center">false</td>
<td align="center">false</td>
<td align="center">true</td>
</tr>
</tbody>
</table>
<table rules="all" frame="border" align="center">
<tbody>
<tr>
<th align="center"></th>
<th align="center"></th>
<th align="center">logical and</th>
<th align="center">logical or</th>
<th align="center">conditional</th>
<th align="center">biconditional</th>
</tr>
<tr>
<th align="center">L $ *P</th>
<th align="center">R $ *P</th>
<th align="center">P == L & R</th>
<th align="center">P == L / R</th>
<th align="center">P == L -&gt; R</th>
<th align="center">P == L &lt;-&gt; R</th>
</tr>
<tr>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">true</td>
</tr>
<tr>
<td align="center">true</td>
<td align="center">false</td>
<td align="center">false</td>
<td align="center">true</td>
<td align="center">false</td>
<td align="center">false</td>
</tr>
<tr>
<td align="center">false</td>
<td align="center">true</td>
<td align="center">false</td>
<td align="center">true</td>
<td align="center">true</td>
<td align="center">false</td>
</tr>
<tr>
<td align="center">false</td>
<td align="center">false</td>
<td align="center">false</td>
<td align="center">false</td>
<td align="center">true</td>
<td align="center">true</td>
</tr>
</tbody>
</table>
@end ifhtml
@end ifset

Since they apply to the final feature structure, constraint expressions
are evaluated after all of the unification and priority union
expressions.  Like unification and unlike priority union, the relative
order of constraints is not (logically) important.

A BNF grammar for PC-PATR logical constraint operations follows.
@example

<logical-constraint> ::= <feature-path> '==' <expression>

<feature-path>       ::= '<' <label-list> '>'

<label-list>         ::= <LABEL>
					   | <LABEL> <label-list>

<expression>         ::=     <factor>
					   | '~' <factor>
					   |     <factor> <binop>     <factor>
					   | '~' <factor> <binop>     <factor>
					   |     <factor> <binop> '~' <factor>
					   | '~' <factor> <binop> '~' <factor>

<factor>             ::= <feature>
					   | '(' <expression> ')'

<binop>              ::= '&'
					   | '/'
					   | '->'
					   | '<->'

<feature>            ::= '[' <attribute-list> ']'
					   | '[]'

<attribute-list>     ::= <attribute>
					   | <attribute> <attribute-list>

<attribute>          ::= <LABEL> ':' <ATOM>
					   | <LABEL> ':' <feature>
					   | <LABEL> ':' <indexedvariable>

<indexedvariable>    ::= '^1'
					   | '^2'
					   | '^3'
					   | '^4'
					   | '^5'
					   | '^6'
					   | '^7'
					   | '^8'
					   | '^9'
@end example
@noindent
Note that both @code{<LABEL>} and @code{<ATOM>} refer to a
single string token of contiguous characters.

@c indexed variables added by hab 08-Mar-2002
An @code{<indexedvariable>} is interpreted as a variable for the
atomic value at that place in the feature structure.  The
first such variable is instantiated by the atomic value of
the feature at that place in the feature-path.  All
subsequent instances of the variable are compared for
equality with the first instantiated one.

Why might one need such an indexed variable?  In some SOV
languages with pro-drop and noun-verb compounding, a clause
consisting just of a @code{Noun Verb} sequence is
potentially at least three ways ambiguous:
@itemize @bullet
@item
@code{Subject Verb}
@item
@i{pro-drop} @code{Object Verb}
@item
@i{pro-drop} @code{Noun-Verb-compound}
@end itemize
In at least one of these languages, it is the case that when
a noun-verb compound is possible, it is the only valid
reading.  Therefore, the correct thing to do is to ensure
that none of the other possible readings are allowed by the
grammar.

Here's a (simplified) example of how one can use indexed
variables to rule out the @code{Subject Verb} case.  (The
@code{Noun} is realized as the @code{DP} node and the
@code{Verb} is realized as a @code{VP} which is a daughter
of the @code{I'} node in the following rule.)
@example
rule @{IP option 2cI - subject initial, required, root clause@}
IP = DP I'
	<IP head> = <I' head>
	<IP head type root> = +
	<IP head type pro-drop> = -
	   ...
	<DP head case nominative> = +
	   ...
	@b{<IP head> == [rootgloss:^1] ->
				 ~ ( [type:[no_intervening:+]] &
				   (( [subject:[head:[type:[compounds_with1:^1]]]]
					/ [subject:[head:[type:[compounds_with2:^1]]]])
					/ ([subject:[head:[type:[compounds_with3:^1]]]]
					/ [subject:[head:[type:[compounds_with4:^1]]]]) ) )}
	   ...
@end example
In the final logical constraint above (which is shown in
bold), the atomic value of the @code{rootgloss} feature is
stored in variable @code{^1} in the antecedent (the "if"
part) of the conditional.  This atomic value is then
compared with the values of the various
@code{compounds_with} features.  The idea is that the value
of the @code{rootgloss} feature should not be any of the
values of the various @code{compounds_with} features (there
are more than one of these because a given noun may compound
with more than one verb).

@c ----------------------------------------------------------------------------
@node Feature templates, Parameter settings, Rules, Grammar file
@section Feature templates

A PC-PATR feature template has these parts, in the order listed:
@enumerate
@item the keyword @code{Let}
@item the template name
@item the keyword @code{be}
@item a feature definition
@item an optional period (@code{.})
@end enumerate
If the template name is a terminal category (a terminal symbol in one
of the phrase structure rules), the template defines the default
features for that category.  Otherwise the template name serves as an
abbreviation for the associated feature structure.

The characters @code{()@{@}[]<>=:} cannot be used in template names
since they are used for special purposes in the grammar file.  The
characters @code{/_} can be freely used in template names.  The
character @code{\} should not be used as the first character of a
template name because that is how fields are marked in the lexicon
file.

The abbreviations defined by templates are usually used in the feature
field of entries in the lexicon file.  For example, the lexical entry
for the irregular plural form @emph{feet} may have the abbreviation
@emph{pl} in its features field.  The grammar file would define this
abbreviation with a template like this:
@example

Let pl be [number: PL]

@end example
@noindent
The path notation may also be used:
@example

Let pl be <number> = PL

@end example
@noindent
More complicated feature structures may be defined in templates.  For
example,
@example

@group
Let 3sg be [tense:  PRES
			agr:    3SG
			finite: +
			vform:  S]
@end group

@end example
@noindent
which is equivalent to:
@example

@group
Let 3sg be <tense>  = PRES
		   <agr>    = 3SG
		   <finite> = +
		   <vform>  = S
@end group

@end example

In the following example, the abbreviation @emph{irreg} is defined using
another abbreviation:
@example

@group
Let irreg be <reg> = -
			 pl
@end group

@end example
@noindent
The abbreviation @emph{pl} must be defined previously in the grammar
file or an error will result.  A subsequent template could also use the
abbreviation @emph{irreg} in its definition.  In this way, an
inheritance hierarchy features may be constructed.

Feature templates permit disjunctive definitions.  For example, the
lexical entry for the word @emph{deer} may specify the feature
abbreviation @emph{sg-pl}.  The grammar file would define this as a
disjunction of feature structures reflecting the fact that the word can
be either singular or plural:
@example

@group
Let sg/pl be @{[number:SG]
			  [number:PL]@}
@end group

@end example
@noindent
This has the effect of creating two entries for @emph{deer}, one with
singular number and another with plural.  Note that there is no limit
to the number of disjunct structures listed between the braces.  Also,
there is no slash (@code{/}) between the elements of the disjunction as
there is between the elements of a disjunction in the rules.
A shorter version of the above template using the path notation looks
like this:
@example

Let sg/pl be <number> = @{SG PL@}

@end example

Abbreviations can also be used in disjunctions, provided that they
have previously been defined:
@example

@group
Let sg be <number> = SG
Let pl be <number> = PL
Let sg/pl be @{[sg] [pl]@}
@end group

@end example
@noindent
Note the square brackets around the abbreviations @emph{sg} and @emph{pl};
without square brackets they would be interpreted as simple values
instead.

Feature templates can assign default atomic feature values, indicated
by prefixing an exclamation point (!).  A default value can be
overridden by an explicit feature assignment.  This template says that
all members of category N have singular number as a default value:
@example

Let N be <number> = !SG

@end example
@noindent
The effect of this template is to make all nouns singular unless they
are explicitly marked as plural.  For example, regular nouns such as
@emph{book} do not need any feature in their lexical entries to signal
that they are singular; but an irregular noun such as @emph{feet} would
have a feature abbreviation such as @emph{pl} in its lexical entry.
This would be defined in the grammar as @w{@code{[number: PL]}}, and would
override the default value for the feature number specified by the
template above.  If the N template above used @code{SG} instead of
@code{!SG}, then the word @emph{feet} would fail to parse, since its
@emph{number} feature would have an internal conflict between @code{SG}
and @code{PL}.

@c ----------------------------------------------------------------------------
@node Parameter settings, Lexical rules, Feature templates, Grammar file
@section Parameter settings

A PC-PATR parameter setting has these parts, in the order listed:
@enumerate
@item the keyword @code{Parameter}
@item an optional colon (@code{:})
@item one or more keywords identifying the parameter
@item the keyword @code{is}
@item the parameter value
@item an optional period (@code{.})
@end enumerate

PC-PATR recognizes the following parameters:
@table @code
@item Start symbol
defines the start symbol of the grammar.  For example,
@example

Parameter Start symbol is S

@end example
@noindent
declares that the parse goal of the grammar is the nonterminal category
S.  The default start symbol is the left hand symbol of the first
phrase structure rule in the grammar file.

@item Restrictor
defines a set of features to use for top-down filtering, expressed as a
list of feature paths.  For example,
@example

Parameter Restrictor is <cat> <head form>

@end example
@noindent
declares that the @emph{cat} and @emph{head form} features should be
used to screen rules before adding them to the parse chart.  The
default is not to use any features for such filtering.  This filtering,
named @emph{restriction} in Shieber (1985), is performed in addition to
the normal top-down filtering based on categories alone.
@sc{restriction is not yet implemented.  should it be instead of
normal filtering rather than in addition to?}

@item Attribute order
specifies the order in which feature attributes are displayed.  For
example,
@example

@group
Parameter Attribute order is cat lex sense head
							 first rest agreement
@end group

@end example
@noindent
declares that the @emph{cat} attribute should be the first one shown
in any output from PC-PATR, and that the other attributes should
be shown in the relative order shown, with the @emph{agreement}
attribute shown last among those listed, but ahead of any attributes
that are not listed above.  Attributes that are not listed are ordered
according to their character code sort order.  If the attribute order
is not specified, then the category feature @emph{cat} is shown first,
with all other attributes sorted according to their character codes.

@item Category feature
defines the label for the category attribute.  For example,
@example

Parameter Category feature is Categ

@end example
@noindent
declares that @emph{Categ} is the name of the category attribute.  The
default name for this attribute is @emph{cat}.

@item Lexical feature
defines the label for the lexical attribute.  For example,
@example

Parameter Lexical feature is Lex

@end example
@noindent
declares that @emph{Lex} is the name of the lexical attribute.  The
default name for this attribute is @emph{lex}.

@item Gloss feature
defines the label for the gloss attribute.  For example,
@example

Parameter Gloss feature is Gloss

@end example
@noindent
declares that @emph{Gloss} is the name of the gloss attribute.  The
default name for this attribute is @emph{gloss}.

@item RootGloss feature
defines the label for the root gloss attribute.  For example,
@example

Parameter RootGloss feature is RootGloss

@end example
@noindent
declares that @emph{RootGloss} is the name of the root gloss attribute.  The
default name for this attribute is @emph{rootgloss}.  Note that this does
not work when using Kimmo to parse words.

@end table

@c ----------------------------------------------------------------------------
@node Lexical rules, Constraint templates, Parameter settings, Grammar file
@section Lexical rules

Lexical rules serve two purposes: providing a flexible means of creating
multiple related lexicon entries, and converting morphological parser
output into a form suitable for syntactic parser input.

@set pc-patr-lex-rule 7
@example

@group
@b{Figure @value{pc-patr-lex-rule}. PC-PATR lexical rule example}

; lexicon entry
\w stormed
\c V
\f Transitive AgentlessPassive
   <head trans pred> = storm

; definitions from the grammar file
Let Transitive be
		<subcat first cat> = NP
		<subcat rest first cat> = NP
		<subcat rest rest> = end
		<head trans arg1> = <subcat first head trans>
		<head trans arg2> = <subcat rest first head trans>.

Define AgentlessPassive as
		<out cat> = <in cat>
		<out subcat> = <in subcat rest>
		<out lex> = <in lex> ; added for PC-PATR
		<out head> = <in head>
		<out head form> => passiveparticiple.
@end group

@end example

@set feat-before 8
@example

@group
@b{Figure @value{feat-before}. Feature structure before lexical rule}

[ lex:    stormed
  cat:    V
  head:   [ trans: [ arg1:  $1 []
					 arg2:  $2 []
					 pred:  storm ] ]
  subcat: [ first: [ cat:   NP
					 head:  [ trans: $1 [] ] ]
			rest:  [ first: [ cat:   NP
							   head: [ trans: $2 [] ] ]
					 rest:  end                      ] ] ]
@end group

@end example

@set feat-after 9
@example

@group
@b{Figure @value{feat-after}. Feature structures after lexical rule}

[ lex:    stormed
  cat:    V
  head:   [ trans: [ arg1:  $1 []
					 arg2:  $2 []
					 pred:  storm ] ]
  subcat: [ first: [ cat:   NP
					 head:  [ trans: $1 [] ] ]
			rest:  [ first: [ cat:   NP
							   head: [ trans: $2 [] ] ]
					 rest:  end                      ] ] ]

[ lex:    stormed
  cat:    V
  head:   [ trans: [ arg1: []
					 arg2: $1 []
					 pred: storm ]
			form:  passiveparticiple ]
  subcat: [ first: [ cat:  NP
					 head: [ trans: $1 [] ] ]
			rest:  end                     ] ]
@end group

@end example

A PC-PATR lexical rule has these parts, in the order listed:

@enumerate
@item the keyword @code{Define}
@item the name of the lexical rule
@item the keyword @code{as}
@item the rule definition
@item an optional period (@code{.})
@end enumerate

The rule definition consists of one or more mappings.  Each mapping has
three parts: an output feature path, an assignment operator, and the
value assigned, either an input feature path or an atomic value.  Every
output path begins with the feature name @code{out} and every input
path begins with the feature name @code{in}.  The assignment operator
is either an equal sign (@code{=}) or an equal sign followed by a
``greater than'' sign (@code{=>}).@footnote{These two operators are
equivalent in PC-PATR, since the implementation treats each
lexical rule as an ordered list of assignments rather than using
unification for the mappings that have an equal sign operator.}

Consider the information shown in figure @value{pc-patr-lex-rule}.  When
the lexicon entry is loaded, it is initially assigned the feature
structure shown in figure @value{feat-before}, which is the unification
of the information given in the various fields of the lexicon entry.
Since one of the the labels stored in the @code{\f} (feature) field is
actually the name of a lexical rule, after the complete feature structure
has been built, the named lexical rule is applied.  After the rule has
been applied, the original single feature structure has been changed to
the two feature structures shown in figure @value{feat-after}.  Note that
not all of the input feature information is found in both of the output
feature structures.

@set pc-kimmo-lex-rule 10
@example

@group
@b{Figure @value{pc-kimmo-lex-rule}. PC-PATR lexical rule for using PC-Kimmo}

Define MapKimmoFeatures as
		<out cat>       = <in head pos>
		<out head>      = <in head>
		<out gloss>     = <in root>
		<out root_pos>  = <in root_pos>
@end group

@end example
@set feat-from-kimmo 11
@example

@group
@b{Figure @value{feat-from-kimmo}. Feature structure received from PC-Kimmo}

[ cat:      Word
  clitic:   -
  drvstem:  -
  head:     [ agr:    [ 3sg: + ]
			  finite: +
			  pos:    V
			  tense:  PRES
			  vform:  S          ]
  root:     `sleep
  root_pos: V                      ]
@end group

@end example

@set feat-to-patr 12
@example

@group
@b{Figure @value{feat-to-patr}. Feature structure sent to PC-PATR}

[ cat:       V
  gloss:     `sleep
  head:      [ agr:    [ 3sg: + ]
			   finite: +
			   pos:    V
			   tense:  PRES
			   vform:  S          ]
  lex:       sleeps
  root_pos: V                       ]
@end group

@end example

Using a lexical rule in conjunction with the PC-Kimmo morphological
parser within PC-PATR is illustrated in
figures @value{pc-kimmo-lex-rule}-@value{feat-to-patr}.
Figure @value{pc-kimmo-lex-rule} shows the lexical rule for mapping from
the top-level feature structure produced by the morphological parser to
the bottom-level feature structure used by the sentence parser.  Note
that this rule must be named @code{MapKimmoFeatures} (unorthodox
capitalization and all).
Figure @value{feat-from-kimmo} shows the feature structure
created by the PC-Kimmo parser.  After the lexical rule shown in
figure @value{pc-kimmo-lex-rule} has been applied (and after some
additional automatic processing), the feature structure shown in
figure @value{feat-to-patr} is passed to the PC-PATR parser.  Note that
only a single feature structure results from this operation, unlike the
result of a lexical rule applied to a lexicon entry.

Note that the feature structure passed to the PC-PATR parser
always has both a @code{lex} feature and a @code{gloss} feature, even
if the @code{MapKimmoFeatures} lexical rule does not create them.  The
default value for the @code{lex} feature is the original word from the
sentence being parsed.  The default value for the @code{gloss} feature
is the concatenation of the glosses of the individual morphemes in the
word.

In contrast to the @code{lex} and @code{gloss} features which are
provided automatically by default, the @code{cat} feature must be
provided by the @code{MapKimmoFeatures} lexical rule.  There is no way
to provide this feature automatically, and it is required for the
phrase structure rule portion of PC-PATR.

@c ----------------------------------------------------------------------------
@node Constraint templates, , Lexical rules, Grammar file
@section Constraint templates

A PC-PATR constraint template has these parts, in the order listed:
@enumerate
@item the keyword @code{Constraint}
@item the template name
@item the keyword @code{is}
@item a logical constraint expression
@item an optional period (@code{.})
@end enumerate

The characters @code{()@{@}[]<>=:/} cannot be used in constraint template
names since they are used for special purposes in the grammar file.  The
characters @code{_\} can be freely used in constraint template names.

The abbreviations defined by constraint templates are used in the logical
constraint operations that are part of the rules defined in the grammar
file.  A constraint template must be defined in the grammar file before
it can be used in a rule.

Consider the following rules in a grammar file:
@example

@group
RULE Word -> Stem
		<Word ms> = <Stem ms>
		<Stem ms> == [finite: +] <-> [tense: []]
@end group

@group
RULE Word -> Stem Infl
		<Word ms> = <Stem ms>
		<Word ms> = <Infl ms>
		<Stem ms> == [finite: +] <-> [tense: []]
@end group

@group
RULE Stem -> Root Deriv
		<Root ms>  = <Deriv msFrom>
		<Stem ms>  = <Root ms>
		<Stem ms> <= <Deriv msTo>
		<Stem ms> == [finite: +] <-> [tense: []]
@end group

@group
RULE Stem -> Root
		<Stem ms> = <Root ms>
		<Stem ms> == [finite: +] <-> [tense: []]
@end group

@end example
@noindent
These rules can be simplied by defining a constraint template:
@example

@group
CONSTRAINT ValidVerb is [finite: +] <-> [tense: []]

RULE Word -> Stem
		<Word ms> = <Stem ms>
		<Stem ms> == ValidVerb
@end group

@group
RULE Word -> Stem Infl
		<Word ms> = <Stem ms>
		<Word ms> = <Infl ms>
		<Stem ms> == ValidVerb
@end group

@group
RULE Stem -> Root Deriv
		<Root ms>  = <Deriv msFrom>
		<Stem ms>  = <Root ms>
		<Stem ms> <= <Deriv msTo>
		<Stem ms> == ValidVerb
@end group

@group
RULE Stem -> Root
		<Stem ms> = <Root ms>
		<Stem ms> == ValidVerb
@end group

@end example

@c ----------------------------------------------------------------------------
@node Standard format, Lexicon file, Grammar file, Top
@chapter Standard format
@cindex standard format

Some of the input control files that PC-PATR reads are @dfn{standard
format} files.  This means that the files are divided into records and
fields.  A standard format file contains at least one record, and some
files may contain a large number of records.  Each record contains one
or more fields.  Each field occupies at least one line, and is marked
by a @dfn{field code} at the beginning of the line.  A field code
begins with a backslash character (@code{\}), and contains 1 or more
printing characters (usually alphabetic) in addition.

If the file is designed to have multiple records, then one of the field
codes must be designated to be the @dfn{record marker}, and every
record begins with that field, even if it is empty apart from the field
code.  If the file contains only one record, then the relative order of
the fields is constrained only by their semantics.

It is worth emphasizing that field codes must be at the
@emph{beginning} of a line.  Even a single space before the backslash
character prevents it from being recognized as a field code.

It is also worth emphasizing that record markers @emph{must} be present
even if that field has no information for that record.  Omitting the
record marker causes two records to be merge into a single record, with
unpredictable results.

@c ----------------------------------------------------------------------------
@node Lexicon file, AMPLE analysis file, Standard format, Top
@chapter The PC-PATR Lexicon File

The lexicon file is a @dfn{standard format}
database file consisting of any number of records,
each of which represents one word.  These records are divided into
fields, each of which begins with a standard format marker at the
beginning of a line.  These markers begin with the @code{\} (backslash)
character followed by one or more alphanumeric characters.  Each record
begins with a designated field.  PC-PATR recognizes four
different fields, with these default field markers:
@table @code
@item \w
the lexical form of the word, spelled exactly as it will
appear in any sentences or phrases input to @w{PC-PATR}@footnote{By
default, @code{\w} also marks the initial field of each word's record.}
@item \c
word category (part of speech)
@item \g
word gloss
@item \f
additional features of this word
@end table
Note that the fields containing the lexical form of the word and its
category must be present for each word (record) in the lexicon.  The
other two fields (glosses and features) are optional, as are additional
fields that may be present for other purposes.

Each word loaded from the lexicon file is assigned certain features
based on the fields described above.
@itemize @bullet
@item The value of the @dfn{lex} feature is the lexical form of the word,
taken from the lexical form field of the word's entry in the lexicon.
@item The value of the @dfn{cat} feature is the lexical category of the word,
for example, Noun, Verb, Adjective, and so on.  This is taken from the
category field of the word's entry in the lexicon.  Note that the same
lexical form can appear multiple times in the lexicon, with a different
category for each occurrence.
@item The value of the @dfn{gloss} feature is the gloss of the word, taken
from the gloss field of the word's entry in the lexicon.  Unlike the
previous two items, this feature is optional.
@end itemize
These feature names should be treated as reserved names and not used
for other purposes.

For example, consider these entries for the words @emph{fox} and
@emph{foxes}:
@example

@group
\w fox
\c N
\g canine
\f <number> = singular

\w foxes
\c N
\g canine+PL
\f <number> = plural
@end group

@end example
@noindent
When these entries are used by the grammar, they are represented by these
feature structures:
@example

@group
[cat:    N
 gloss:  canine
 lex:    foxes
 number: singular]

[cat:    N
 gloss:  canine+PL
 lex:    foxes
 number: plural]
@end group

@end example
@noindent
The lexicon entries can be simplified by defining feature templates in
the grammar file.  Consider the following templates:
@example

@group
Let PL be <number> = plural
Let N  be <number> = !singular
@end group

@end example
@noindent
With these two templates, defining an abbreviation for ``plural'' and
defining a default feature for category N (noun), the lexicon entries
can be rewritten as follows:
@example

@group
\w fox
\c N
\g canine
\f

\w foxes
\c N
\g canine+PL
\f PL
@end group

@end example
@noindent
Note that the feature (@code{\f}) field of the first entry could be
omitted altogether since it is now empty.

@c ----------------------------------------------------------------------------
@node AMPLE analysis file, Using morphological parsers, Lexicon file, Top
@chapter The AMPLE Analysis File

Rather than using a dedicated lexicon file, PC-PATR can load its
internal lexicon from one or analysis files produced by the AMPLE
morphological analysis program.  AMPLE writes a standard format
database for its output, each record of which corresponds to a word of
the source text.  The first field of each entry contains the analysis.
Other fields, which may or may not occur, contain additional
information.

The utility of this command has been greatly reduced by the
availability of the @w{@code{load ample}} and @w{@code{load kimmo}}
commands which allow morphological analysis on demand to populate
PC-PATR's word lexicon.  However, the @w{@code{file disambiguate}}
command also operates on AMPLE analysis files, so this information is
still of interest.

@menu
* AMPLE analysis file fields::
* Ambiguous analyses::
* Analysis failures::
@end menu

@c ----------------------------------------------------------------------------
@node AMPLE analysis file fields, Ambiguous analyses, AMPLE analysis file, AMPLE analysis file
@section AMPLE analysis file fields

This section describes the fields that AMPLE writes to the output
analysis file.  The only field that is guaranteed to exist is the
analysis (@code{\s}) field.  All other fields are either data dependent
or optional.

@menu
* \a::              Analysis
* \d::              Decomposition (surface forms)
* \cat (.ANA)::     Category (possible word, morpheme)
* \p::              Properties
* \fd::             Feature Descriptors
* \u::              Underlying forms (decomposition)
* \w::              Word (before decapitalization and orthography changes)
* \f::              Formatting (junk before the word)
* \c::              Capitalization flag
* \n::              Nonalphabetic (junk after the word)
@end menu

@c ----------------------------------------------------------------------------
@node \a, \d, AMPLE analysis file fields, AMPLE analysis file fields
@subsection Analysis: \a
@findex \a

The analysis field (@code{\a}) starts each record of the output
analysis file.  It has the following form:
@example

\a PFX IFX PFX < CAT root CAT root > SFX IFX SFX

@end example
@noindent
where @code{PFX} is a prefix morphname, @code{IFX} is an infix
morphname, @code{SFX} is a suffix morphname, @code{CAT} is a root
category, and @code{root} is a root gloss or etymology.  In the
simplest case, an analysis field would look like this:
@example

\a < CAT root >

@end example

The @code{\rd} field in the analysis data file can replace the
characters used to bracket the root category and gloss/etymology; see
@ifset txt
`Root Delimiter Characters: \rd' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{\rd, , Root Delimiter Characters: \rd,
	 ample.info, AMPLE Reference Manual}.
@end ifclear
The dictionary field code mapped to @code{M} in the dictionary codes
file controls the affix and default root morphnames; see
@ifset txt
`Morphname (internal code M)' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{Morphname, , Morphname (internal code M),
	 ample.info, AMPLE Reference Manual}.
@end ifclear
If the AMPLE @samp{-g} command line option was given, the output analysis file
contains glosses from the root dictionary marked by the field code
mapped to @code{G} in the dictionary codes file; see
@ifset txt
`AMPLE Command Options'
@end ifset
@ifclear txt
@ref{Command options, , AMPLE Command Options,
	 ample.info, AMPLE Reference Manual},
@end ifclear
and
@ifset txt
`Root Gloss (internal code G)' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{Root gloss, , Root Gloss (internal code G),
	 ample.info, AMPLE Reference Manual}.
@end ifclear

@c ----------------------------------------------------------------------------
@node \d, \cat (.ANA), \a, AMPLE analysis file fields
@subsection Decomposition (surface forms): \d
@findex \d

The morpheme decomposition field (@code{\d}) follows the analysis
field.  It has the following form:
@example

\d anti-dis-establish-ment-arian-ism-s

@end example
@noindent
where the hyphens separate the individual morphemes in the surface form
of the word.

The @code{\dsc} field in the text input control file can replace the
hyphen with another character for separating the morphemes; see
@ifset txt
`Decomposition Separation Character: \dsc' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{\dsc, , Decomposition Separation Character: \dsc,
	 ample.info, AMPLE Reference Manual}.
@end ifclear

The morpheme decomposition field is optional.  It is enabled either by
an AMPLE @w{@samp{-w d}} command line option
@ifset txt
(see `AMPLE Command Options' in the AMPLE Reference Manual),
@end ifset
@ifclear txt
(@pxref{Command options, , AMPLE Command Options,
	 ample.info, AMPLE Reference Manual}),
@end ifclear
or by an interactive query.

@c ----------------------------------------------------------------------------
@node \cat (.ANA), \p, \d, AMPLE analysis file fields
@subsection Category (possible word or morpheme): \cat
@findex \cat

The category field (@code{\cat}) provides rudimentary category
information.  It has the following form:
@example

\cat CAT

@end example
@noindent
where @code{CAT} is the proposed word category.  A more complex example
is
@example

\cat C0 C1/C0=C2=C2/C1=C1/C1

@end example
@noindent
where @code{C0} is the proposed word category, @code{C1/C0} is a prefix
category pair, @code{C2} is a root category, and @code{C2/C1} and
@code{C1/C1} are suffix category pairs.  The equal signs (@code{=})
serve to separate the category information of the individual morphemes.

The @code{\cat} field of the analysis data file controls whether the
category field is written to the output analysis file; see
@ifset txt
`Category output control: \cat' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{\cat, , Category output control: \cat,
	 ample.info, AMPLE Reference Manual}.
@end ifclear

@c ----------------------------------------------------------------------------
@node \p, \fd, \cat (.ANA), AMPLE analysis file fields
@subsection Properties: \p
@findex \p

The properties field (@code{\p}) contains the names of any allomorph or
morpheme properties found in the analysis of the word.  It has the
form:
@example

\p ==prop1 prop2=prop3=

@end example
@noindent
where @code{prop1}, @code{prop2}, and @code{prop3} are property names.
The equal signs (@code{=}) serve to separate the property information
of the individual morphemes.  Note that morphemes may have more than
one property, with the names separated by spaces, or no properties at
all.

By default, the properties field is written to the output analysis
file.  The @w{@samp{-w 0}} command option, or any @samp{-w} option that
does not include @samp{p} in its argument disables the properties field.

@c ----------------------------------------------------------------------------
@node \fd, \u, \p, AMPLE analysis file fields
@subsection Feature Descriptors: \fd
@findex \fd

The feature descriptor field (@code{\fd}) contains the feature names
associated with each morpheme in the analysis.  It has the following
form:
@example

\fd ==feat1 feat2=feat3=

@end example
@noindent
where @code{feat1}, @code{feat2}, and @code{feat3} are feature
descriptors.  The equal signs (@code{=}) serve to separate the feature
descriptors of the individual morphemes.  Note that morphemes may have
more than one feature descriptor, with the names separated by spaces,
or no feature descriptors at all.

The dictionary field code mapped to @code{F} in the dictionary code
table file controls whether feature descriptors are written to the
output analysis file; if this mapping is not defined, then the
@code{\fd} field is not written.
@ifset txt
See `Feature Descriptor (internal code F)' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@xref{Feature descriptor, , Feature Descriptor (internal code F),
	 ample.info, AMPLE Reference Manual}.
@end ifclear

@c ----------------------------------------------------------------------------
@node \u, \w, \fd, AMPLE analysis file fields
@subsection Underlying forms (decomposition): \u
@findex \u

The underlying form field (@code{\u}) is similar to the decomposition
field except that it shows underlying forms instead of surface forms.
It looks like this:
@example

\u a-para-a-i-ri-me

@end example
@noindent
where the hyphens separate the individual morphemes.

The @code{\dsc} field in the text input control file can replace the
hyphen with another character for separating the morphemes; see
@ifset txt
`Decomposition Separation Character: \dsc' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{\dsc, , Decomposition Separation Character: \dsc,
	 ample.info, AMPLE Reference Manual}.
@end ifclear

The dictionary field code mapped to @code{U} in the dictionary code
table file controls whether underlying forms are written to the output
analysis file; if this mapping is not defined, then the @code{\u} field
is not written.
@ifset txt
See `Underlying Form (internal code U)' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{Underlying form, , Underlying Form (internal code U),
	 ample.info, AMPLE Reference Manual}.
@end ifclear

@c ----------------------------------------------------------------------------
@node \w, \f, \u, AMPLE analysis file fields
@subsection Word (before decapitalization and orthography changes): \w
@findex \w

The original word field (@code{\w}) contains the original input word as
it looks before decapitalization and orthography changes.  It looks
like this:
@example

\w The

@end example
@noindent
Note that this is a gratuitous change from earlier versions of AMPLE,
which wrote the decapitalized form.

The original word field is optional.  It is enabled either by
an AMPLE @w{@samp{-w w}} command line option
@ifset txt
(see `AMPLE Command Options' in the AMPLE Reference Manual),
@end ifset
@ifclear txt
(@pxref{Command options, , AMPLE Command Options,
	 ample.info, AMPLE Reference Manual}),
@end ifclear
or by an interactive query.

@c ----------------------------------------------------------------------------
@node \f, \c, \w, AMPLE analysis file fields
@subsection Formatting (junk before the word): \f
@findex \f

The format information field (@code{\f}) records any formatting codes
or punctuation that appeared in the input text file before the word.
It looks like this:
@example

@group
\f \\id MAT 5 HGMT05.SFM, 14-feb-84 D. Weber, Huallaga Quechua\n
		\\c 5\n\n
		\\s
@end group

@end example
@noindent
where backslashes (@code{\}) in the input text are doubled, newlines
are represented by @code{\n}, and additional lines in the field start
with a tab character.

The format information field is written to the output analysis file
whenever it is needed, that is, whenever formatting codes or
punctuation exist before words.

@c ----------------------------------------------------------------------------
@node \c, \n, \f, AMPLE analysis file fields
@subsection Capitalization flag: \c
@findex \c

The capitalization field (@code{\c}) records any capitalization of the
input word.  It looks like this:
@example

\c 1

@end example
@noindent
where the number following the field code has one of these values:
@table @code
@item 1
the first (or only) letter of the word is capitalized

@item 2
all letters of the word are capitalized

@item 4@value{endash}32767
some letters of the word are capitalized and some are not
@end table
@noindent
Note that the third form is of limited utility, but still exists
because of the author's last name.

The capitalization field is written to the output analysis file
whenever any of the letters in the word are capitalized; see
@ifset txt
`Prevent Any Decapitalization: \nocap'
@end ifset
@ifclear txt
@ref{\nocap, , Prevent Any Decapitalization: \nocap,
	 ample.info, AMPLE Reference Manual},
@end ifclear
and
@ifset txt
`Prevent Decapitalization of Individual Characters: \noincap' in the
AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{\noincap, , Prevent Decapitalization of Individual Characters: \noincap,
	 ample.info, AMPLE Reference Manual}.
@end ifclear

@c ----------------------------------------------------------------------------
@node \n, , \c, AMPLE analysis file fields
@subsection Nonalphabetic (junk after the word): \n
@findex \n

The nonalphabetic field (@code{\n}) records any trailing punctuation,
bar code
@ifset txt
(see `Bar Code Format Code Characters: \barcodes' in the AMPLE Reference
Manual),
@end ifset
@ifclear txt
(@pxref{\barcodes, , Bar Code Format Code Characters: \barcodes,
	 ample.info, AMPLE Reference Manual}),
@end ifclear
or whitespace characters.  It looks like this:
@example

\n |r.\n

@end example
where newlines are represented by @code{\n}.  The nonalphabetic field
ends with the last whitespace character immediately following the word.

The nonalphabetic field is written to the output analysis file whenever
the word is followed by anything other than a single space character.
This includes the case when a word ends a file with nothing following
it.

@c ----------------------------------------------------------------------------
@node Ambiguous analyses, Analysis failures, AMPLE analysis file fields, AMPLE analysis file
@section Ambiguous analyses

The previous section assumed that AMPLE produced only one analysis for
a word.  This is not always possible since words in isolation are
frequently ambiguous.  AMPLE handles multiple analyses by writing each
analysis field in parallel, with the number of analyses at the
beginning of each output field.  For example,
@example

@group
\a %2%< A0 imaika > CNJT AUG%< A0 imaika > ADVS%
\d %2%imaika-Npa-ni%imaika-Npani%
\cat %2%A0 A0=A0/A0=A0/A0%A0 A0=A0/A0%
\p %2%==%=%
\fd %2%==%=%
\u %2%imaika-Npa-ni%imaika-Npani%
\w Imaicampani
\f \\v124
\c 1
\n \n
@end group

@end example
@noindent
where the percent sign (@code{%}) separates the different analyses in
each field.  Note that only those fields which contain analysis
information are marked for ambiguity.  The other fields (@code{\w},
@code{\f}, @code{\c}, and @code{\n}) are the same regardless of the
number of analyses that AMPLE discovers.

The @code{\ambig} field in the text input control file can replace the
percent sign with another character for separating the analyses; see
@ifset txt
`Ambiguity Marker Character: \ambig' in the AMPLE Reference Manual
@end ifset
@ifclear txt
@ref{\ambig, , Ambiguity Marker Character: \ambig,
	 ample.info, AMPLE Reference Manual},
@end ifclear
for details.

@c ----------------------------------------------------------------------------
@node Analysis failures, , Ambiguous analyses, AMPLE analysis file
@section Analysis failures

The previous sections assumed that AMPLE successfully analyzed a word.
This does not always happen.  AMPLE marks analysis failures the same
way it marks multiple analyses, but with zero (@code{0}) for the
ambiguity count.  For example,
@example

@group
\a %0%ta%
\d %0%ta%
\cat %0%%
\p %0%%
\fd %0%%
\u %0%%
\w TA
\f \\v 12 |b
\c 2
\n |r\n
@end group

@end example
@noindent
Note that only the @code{\a} and @code{\d} fields contain any analysis
information, and those both have the decapitalized word as a place
holder.

The @code{\ambig} field in the text input control file can replace the
percent sign with another character for marking analysis failures and
ambiguities; see
@ifset txt
`Ambiguity Marker Character: \ambig' in the AMPLE Reference Manual.
@end ifset
@ifclear txt
@ref{\ambig, , Ambiguity Marker Character: \ambig,
	 ample.info, AMPLE Reference Manual}, for details.
@end ifclear

@c ----------------------------------------------------------------------------
@node Using morphological parsers, Index, AMPLE analysis file, Top
@chapter Using the Embedded Morphological Parsers

Normally, PC-PATR requires the linguist to develop a full-fledged
lexicon of words with their features.  This may be unnecessary if a
morphological analysis, and a comprehensive lexicon of morphemes, has
already been developed using either PC-Kimmo (version 2) or AMPLE
(version 3).  These morphological parsing programs are also available
from SIL.

@menu
* PC-Kimmo::
* AMPLE::
@end menu

@c ----------------------------------------------------------------------------
@node PC-Kimmo, AMPLE, Using morphological parsers, Using morphological parsers
@section PC-Kimmo

Version 2 of PC-Kimmo supports a PC-PATR style grammar for defining
word structure in terms of morphemes.  This provides a straightforward
way to obtain word features as a result of the morphological analysis
process.  For best results, the (PC-Kimmo) word grammar and the
(PC-PATR) sentence or phrase grammar should be developed together.

When using the PC-Kimmo morphological parser, PC-PATR requires a
special lexical rule in the (sentence level) grammar file.
This rule is named @code{MapKimmoFeatures} and is used automatically to
map from the features produced by the word parse to the features needed
by the sentence parse.  For example, consider the following definition:
@example

@group
Define MapKimmoFeatures as
		<out cat>       = <in head pos>
		<out lex>       = <in lex>
		<out head>      = <in head>
@end group

@end example
This lexical rule uses the @w{@code{<head pos>}} feature produced by the
PC-Kimmo parser as the @code{<cat>} feature for the PC-PATR
parser, and passes the @code{<lex>} and @code{<head>} features from the
morphological parser to the sentence parser unchanged.

@c ----------------------------------------------------------------------------
@node AMPLE, , PC-Kimmo, Using morphological parsers
@section AMPLE

The only thing necessary to use the AMPLE morphological parser
inside PC-PATR is to load the appropriate control files and
dictionaries.  This will not be too useful, however, unless the
AMPLE dictionaries contain feature descriptors to pass through to
PC-PATR.  It is also required for the AMPLE data to define
the word category.  (Either the word-final suffix category or the
word-initial prefix category can be designated in the analysis data
file).  Consult the AMPLE documentation for more details on either
of these issues.

@c ----------------------------------------------------------------------------
@node Index, , Using morphological parsers, Top
@chapter Index

@printindex cp

@c ----------------------------------------------------------------------------
@contents
@bye
